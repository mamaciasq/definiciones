[
["index.html", "Teoría de indicadores 1 Prerequisitos", " Teoría de indicadores Dirección Nacional de Planeación y Estadística 2017-12-17 1 Prerequisitos Este es un libro escrito en formato Markdown que permite vincular textos, imágenes, fórmulas matemáticas y referencias textuales. Su potencial se debe a la inclusión de Pandoc dentro de documentos creados desde R. Se usa la librería bookdown (Xie, 2016), la cual fue construida bajo la librería knitr (Xie, 2015) Cada archivo Rmd contiene solo un capítulo, y un capítulo se define por el encabezamiento de primer nivel #. Para compilar este libro en PDF, necesitará instalarse XeLaTeX. Referencias "],
["intro.html", " 2 Introducción", " 2 Introducción Se pensó en construir este opúsculo para la construcción del documento metodológico que servirá como base teórica del proyecto Fortalecimiento de la actividad estadística institucional. Aquí se intentan documentar algunas acepciones, documentos digitales, referencias bibliográficas y demás información que pueda ayudar a entender conceptualmente los objetivos y alcances de este proyecto. La estructura que se siguió para construir este libro fue la siguiente: primero se consultó con profesores del Departamento de Estadística con el fin de obtener sus percepciones, ideas y bibliografía relacionados con indicadores estadísticos en educación, luego se hizo una revisión de la literatura referente a los temas de interés del proyecto y, finalmente, se convinieron algunas acepciones y significados de los términos que se enmarcan en el Sistema conceptual básico con textos que constituyen el acervo bibliográfico de esta parte teórica del proyecto. "],
["consulta-con-profesores.html", " 3 Consulta con profesores", " 3 Consulta con profesores Con el ánimo de enriquecer el acopio de esta información, se consultó a los profesores Jorge Humberto Mayorga Álvarez, Nelcy Rodríguez Malagón, Diana Carolina Franco Soto, Álvaro Mauricio Montenegro, entre otros, quienes han realizado trabajos de aproximación conceptual de los temas de interés del proyecto. Véase Mayorga Álvarez (2004), Morales &amp; Zárate (2004), Soto &amp; Franco (2009) y Castro et al. (2009). El profesor Mayorga animó el desarrollo de este trabajo por considerarlo de gran aporte a la ciencia estadística. Animó a “reflexionar sobre la estructura matemática y estadística de los indicadores, unificando su significado, pues se encuentran diversas presentaciones particulares que son débiles en sus argumentos” En este sentido, se convino primero en hacer una revisión de la literatura existente desde diversos enfoques (cognitivo, estadístico, epidemiológico, demográfico, social, etc.) para luego abordarlo desde la estructura matemática. Como este documento tiene un enfoque educativo en el sentido de que su contexto está ubicado en la Universidad Nacional de Colombia, las acepciones, significados y demás estarán orientados principalmente en términos de la educación. Referencias "],
["sistema-conceptual-basico.html", " 4 Sistema conceptual básico", " 4 Sistema conceptual básico «A menudo digo que cuando puede medirse y expresarse en números lo que se está describiendo, se sabe algo. Si aquello de lo que se habla no puede medirse o ser expresado en números, el conocimiento sobre ello es generalmente escaso e insatisfactorio». — Lord Kelvin, 1891 "],
["variable.html", "4.1 Variable", " 4.1 Variable Una variable está conformada por dos componentes, una unidad estadística y una propiedad. Una unidad estadística es la unidad de observación o de medida para la cual los datos se recolectan o se derivan (e.g. personas u hogares en encuestas sociales, y empresas o establecimientos en encuestas de negocios). Una propiedad es una característica o atributo de la unidad estadística. Las definiciones de variables deben ser inequívocas y claramente especificadas en el contexto de los propósitos analíticos para los cuales los datos se recolectan. Soto &amp; Franco (2009) y Everitt (2006). La clasificación es un agrupamiento sistemático de valores que puede tomar una variable que comprende clases que se excluyen mutuamente, cubriendo el conjunto completo de valores, proporcionando a menudo una estructura jerárquica para la agregación de datos a fin de facilitar el análisis y la interpretación. Se puede utilizar más de una clasificación para representar datos para una variable dada. Existen multiplicidad de clasificaciones de las variables, sin embargo, en este texto se abordarán tres de ellas: por su carácter métrico, su carácter matemático y su grado de influencia. Desde el enfoque de su esencia métrica, las variables se dividen en cualitativas y cuantitativas. Las cualitativas se refieren a aquellas cuyas características de variación poseen un caracter asociado a sus cualidades que no son susceptibles a medirse numéricamente. Las cuantitativas son aquellas cuyas propiedades pueden presentarse en distintas intensidades o grados de forma numérica. De acuerdo con su índole matemática, las variables cuantitativas se distinguen entre discretas y continuas. Las variables cuantitativas discretas son aquellas que se definen sobre rangos finitos o infinitos numerables. Su rasgo distintivo es que no pueden tomar valores intermedios entre dos valores dados. Las continuas son aquellas variables que están definidas sobre rangos infinitos no numerables. Pueden tomar valores dentro de un recorrido determinado. Según su grado de influencia pueden ser dependientes o independientes. Las primeras son las variables de respuesta observadas en un estudio y que son influenciadas por los valores de las variables independientes. Las variables independientes son aquellas características o propiedades que se supone son la causa del fenómeno estudiado. A estas variables se les suele asignar valores arbitrarios. Para la conceptualización de razones, proporciones y tasas se acudirá a los desarrollos hechos desde el campo de la medicina. Referencias "],
["razones.html", "4.2 Razones", " 4.2 Razones Desde el punto de vista matemático, una razón es una relación binaria Levy (2002) entre magnitudes (objetos, profesores, estudiantes, etc.), que comúnmente se expresa como “a es a b” o a:b. Toda razón puede expresarse como una fracción. 4.2.1 Razones aritméticas y geométricas Algunas veces suele hablarse de razón aritmética y razón geométrica en el contexto de las progresiones aritméticas y progresiones geométricas, respectivamente. En ambos casos, la razón se entiende como la relación entre dos términos consecutivos de la sucesión, antecedente y consecuente, siendo esta relación la diferencia en el caso de las progresiones aritméticas y el cociente en el caso de las progresiones geométricas. Tradicionalmente se ha denominado exponente o exponente de la razón al número resultado de esta diferencia o cociente Rosell (1785); Verdejo Páez &amp; others (1851). En particular, una razón puede escribirse como un número dividido en otro (una fracción) de la forma \\(a/b\\). Tanto \\(a\\) como \\(b\\) se refieren a la frecuencia de algún evento u ocurrencia. 4.2.2 Razón aritmética Es la diferencia de dos cantidades. Comúnmente se escribe así, la razón aritmética de 8 a 6 se escribe: 8.6 o 8-6. El primer término recibe el nombre de antecedente y el segundo el de consecuente. Así en la razón 6-4, el antecedente es 6 y el consecuente 4. 4.2.3 Razón geométrica Es la comparación de dos cantidades por su cociente. La interpretación dice cuántas veces contiene una a la otra. Únicamente si las magnitudes a comparar tienen la misma unidad de medida la razón es adimensional. Una razón \\(«X:Y»\\) puede leerse como \\(«X\\) sobre \\(Y»\\), o \\(«X\\) es a \\(Y»\\). El numerador de la razón (es decir, el \\(X\\)) se llama antecedente y al denominador (el \\(Y\\)) se le conoce como consecuente. Ejemplo 21:7 representa la razón de 21 entre 7, que es igual a 3 (21 tiene tres veces 7). Su razón geométrica es 3, su antecedente 21, y su consecuente 7. El artículo de Atchley, Gaskins, &amp; Anderson (1976) profundiza sobre las propiedades estadísticas de la razón mediante unos resultados empíricos. Referencias "],
["proporciones.html", "4.3 Proporciones", " 4.3 Proporciones Una proporción se define matemáticamente como la razón de los valores en un subconjunto \\(S\\) a los valores en un conjunto \\(R\\). Como tal la proporción de la población puede definirse así: \\[P = \\frac {X}{N}\\] donde \\(X\\) cuenta los “éxitos” en la población y \\(N\\) es el tamaño de la población. Esta definición matemática puede generalizarse para proporcionar la definición de la proporción de la muestra: \\(\\hat{p}=\\frac{x}{n}\\) donde \\(x\\) es el recuento de éxitos en la muestra y \\(n\\) es el tamaño de la muestra obtenida de la población (Weisstein, 2002). 4.3.1 Estimación Uno de los principales focos de estudio en la estadística inferencial es determinar el valor “verdadero” de un parámetro. En general, el valor real de un parámetro nunca se encontrará a menos que se realice un censo sobre la población de estudio. Sin embargo, existen métodos estadísticos que pueden utilizarse para obtener una estimación razonable de un parámetro. Estos métodos incluyen intervalos de confianza y pruebas de hipótesis. La estimación del valor de una proporción de población puede ser de gran implicación en las áreas de agricultura, negocios, economía, educación, ingeniería, estudios ambientales, medicina, derecho, ciencias políticas, psicología y sociología. Una proporción de la población se puede estimar mediante el uso de un intervalo de confianza conocido como proporción de una muestra en el intervalo \\(Z\\) cuya fórmula se da a continuación: \\[\\hat{p} \\pm z*\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\] donde \\(\\hat{p}\\) es la proporción muestral, \\(n\\) es el tamaño de la muestra y \\(z^*\\) es el valor crítico superior \\(\\frac{1-C}{2}\\) de la distribución normal estándar para un nivel de confianza \\(C\\). (Mayorga Álvarez, 2004) 4.3.2 Condiciones para la inferencia En general, la fórmula utilizada para estimar una proporción de la población requiere sustituciones de valores numéricos conocidos. Sin embargo, estos valores numéricos no pueden ser “ciegamente” sustituidos en la fórmula porque la inferencia estadística requiere que la estimación de un parámetro desconocido sea justificable. Para que se cumpla esta condición, hay tres condiciones que deben ser verificadas: La observación individual de los datos debe obtenerse a partir de una muestra aleatoria simple (MAS) de la población de interés. Las observaciones individuales de los datos tienen que mostrar normalidad. Las observaciones individuales de los datos deben ser independientes entre sí. 4.3.3 Errores comunes y malas interpretaciones de la estimación Un error muy común que surge de la construcción de un intervalo de confianza es la creencia de que un nivel de confianza tal como \\(C = 95\\%\\) significa el \\(95\\%\\) de probabilidad. Esto es incorrecto. El nivel de confianza se basa en una medida de certeza, no de probabilidad. Por lo tanto, los valores de \\(C\\) se encuentran entre 0 y 1, exclusivamente. Referencias "],
["tasas.html", "4.4 Tasas", " 4.4 Tasas Una tasa es la relación entre dos cantidades relacionadas. Si el denominador de la relación se expresa como una sola unidad de una de estas cantidades, y si se supone que esta cantidad se puede cambiar sistemáticamente (es decir, es una variable independiente), entonces el numerador de la relación expresa la tasa correspondiente de cambio en la otra variable (dependiente). El tipo más común de tasa es “por unidad de tiempo”, como velocidad, frecuencia cardíaca y flujo. Las razones que tienen un denominador que no se relaciona con el tiempo incluyen tipos de cambio, tasas de alfabetización y campo eléctrico. Al describir las unidades de una velocidad, se utiliza la palabra “por” para separar las unidades de las dos mediciones utilizadas para calcular la velocidad (por ejemplo, una frecuencia cardiaca se expresa “latidos por minuto”). Una tasa definida utilizando dos números de las mismas unidades (como las tasas de impuestos) o recuentos (como la tasa de alfabetización) dará lugar a una cantidad adimensional, que puede expresarse como un porcentaje (por ejemplo, la tasa de alfabetización global en 1998 fue de 80 %) o fracción o como un múltiplo. Las tasas y las razones a menudo varían con el tiempo, ubicación, elemento particular (o subconjunto) de un conjunto de objetos, etc. Así, a menudo son funciones matemáticas. Por ejemplo, \\(v(x)\\) puede representar la velocidad \\(v\\) (distancia recorrida por unidad de tiempo) de un vehículo de transporte en un viaje determinado como una función de \\(x\\) (la distancia recorrida desde el inicio del viaje). Alternativamente, se podría expresar la velocidad en función del tiempo \\(t\\) desde el inicio del viaje como \\(v(t)\\). Otra representación de la velocidad en un viaje es particionar la ruta de viaje en \\(N\\) segmentos y dejar que vi sea la velocidad constante en el segmento \\(i\\) (\\(v\\) es una función del índice \\(i\\)). Aquí cada segmento \\(i\\), del viaje es un subconjunto de la ruta de viaje. A menudo se puede pensar en una tasa (o proporción), ya que las tasas unitarias son muy sencillas, se advierte la relación entre el consumo y el ingreso, relación beneficio-costo, todo considerado en sentido amplio. Por ejemplo, millas por hora en el transporte es la salida (o beneficio) en términos de millas de viaje, que se obtiene de pasar una hora (un coste en el tiempo) de viajar (a esta velocidad). Se puede usar un conjunto de índices secuenciales \\(i\\) para enumerar elementos (o subconjuntos) de un conjunto de relaciones en estudio. Por ejemplo, en finanzas, se podría definir \\(i\\) asignando números enteros consecutivos a empresas, a subdivisiones políticas (tales como estados), a diferentes inversiones, etc. La razón para usar los índices \\(i\\) es un conjunto de razones (\\(i = 0, N\\)) se puede utilizar en una ecuación para calcular una función de las tasas tales como un promedio de un conjunto de relaciones. Por ejemplo, la velocidad media encontrada a partir del conjunto de \\(v_i\\) mencionado anteriormente. Encontrar promedios puede implicar el uso de promedios ponderados y posiblemente usando la media armónica. Una relación \\(r = a / b\\) tiene tanto un numerador \\(a\\) y un denominador \\(b\\). \\(a\\) y/o \\(b\\) pueden ser un número real o entero. La inversa de una tasa \\(r\\) es \\(1 / r = b / a\\). 4.4.1 Tasa de cambio Considere el caso en el que el numerador \\(f\\) de una razón es una función \\(f(a)\\) donde \\(a\\) pasa a ser el denominador de la tasa \\(\\partial f / \\partial a\\). Una tasa de cambio de \\(f\\) con respecto a \\(a\\) (donde \\(a\\) se incrementa por \\(h\\)) puede ser formalmente definida de dos formas: \\[\\text{Tasa de cambio promedio}=\\frac{f(a+h)-f(a)}{h}\\] \\[\\text{Tasa de cambio instantanea}=\\lim_{h \\to 0} \\frac{f(a+h)-f(a)}{h}\\] donde \\(f(x)\\) es la función con respecto a \\(x\\) sobre el intervalo de \\(a\\) a \\(a + h\\). Una tasa instantánea de cambio es equivalente a una derivada. Un ejemplo para contrastar las diferencias entre las tasas unitarias son definiciones inmediatas: la velocidad de un automóvil puede calcularse: Se puede calcular una tasa media utilizando la distancia total recorrida entre \\(a\\) y \\(b\\), dividida por el tiempo de viaje. Con el fin de tener herramientas estadísticas completas para la evaluación de tasas y proporciones, adjunto a este documento está Fleiss, Levin, &amp; Paik (2013) donde pueden encontrarse los métodos estadísticos para su evaluación. Referencias "],
["porcentajes.html", "4.5 Porcentajes", " 4.5 Porcentajes En matemáticas, un porcentaje es un número o razón expresada como una fracción de 100. Se denota con el símbolo de porcentaje (\\(\\%\\)). Un porcentaje es una cantidad adimensional. 4.5.1 Cálculos No sobra exponer la forma correcta de cálculo de porcentajes para disipar cualquier duda que exista. El valor porcentual se calcula multiplicando el valor numérico de la razón por 100. Por ejemplo, para encontrar 50 manzanas como un porcentaje de 1250 manzanas, primero se calcula la relación \\(50/1250 = 0.04\\), y luego se multiplica por 100 para obtener \\(4\\%\\). El valor porcentual también se puede encontrar multiplicando primero, de modo que en este ejemplo el 50 se multiplicaría por 100 para dar 5.000, y este resultado sería dividido por 1250 para dar el mismo \\(4\\%\\). Para calcular un porcentaje de un porcentaje, deben conviertirse ambos porcentajes en fracciones de 100 o en decimales y luego multiplicarlos. Por ejemplo, el 50% del 40% es: \\(50/100 \\times 40/100 = 0,50 \\times 0,40 = 0,20 = 20/100 = 20\\%.\\) No es correcto dividir por 100 y usar el signo de porcentaje al mismo tiempo. (Por ejemplo, 25% = 25/100 = 0,25, no es 25% / 100, que en realidad es \\(\\frac{\\frac{25}{100}}{100} = 0,0025\\). Un término tal como \\(\\frac{100}{100}\\%\\) también sería incorrecto, esto se leería como 1 por ciento incluso si La intención era decir 100%.) Cada vez que se habla de un porcentaje, es importante especificar lo que es relativo a, es decir, que es el total al que corresponde al 100%. El siguiente problema ilustra este punto. En una universidad determinada, el 60% de todos los estudiantes son mujeres, y el 10% de todos los estudiantes son maestros de ciencias de la computación. Si el 5% de las estudiantes son estudiantes de ciencias de la computación, ¿qué porcentaje de estudiantes de ciencias de la computación son mujeres? Se pide calcular la proporción de mujeres estudiantes de ciencias de la computación de todos los estudiantes de ciencias de la computación. Se sabe que el 60% de todos los estudiantes son mujeres, y entre estos 5% son estudiantes de ciencias de la computación, por lo que se concluye que 60/100 × 5/100 = 3/100 o 3% de todos los estudiantes son estudiantes de ciencias de la computación. Dividiendo esto por el 10% de todos los estudiantes que son maestros de ciencias de la computación, se llega a la respuesta: 3% / 10% = 30/100 o 30% de todos los estudiantes de ciencias de la computación son mujeres. 4.5.2 Aumento y disminuación porcentual Debido al uso incorrecto, no siempre está claro desde el contexto a qué se refiere un porcentaje. Cuando se habla de una “subida del 10%” o de una “caída del 10%” en una cantidad, la interpretación habitual es que ésta es relativa al valor inicial de esa cantidad. Por ejemplo, si un artículo tiene un precio inicial de \\(\\$200\\) y el precio sube 10% (un aumento de \\(\\$20\\)), el nuevo precio será de \\(\\$ 220\\). Debe tenerse en cuenta que este precio final es el \\(110\\%\\) del precio inicial (\\(100\\% + 10\\% = 110\\%\\)). Algunos otros ejemplos de cambios porcentuales: Un aumento del \\(100\\%\\) en una cantidad significa que la cantidad final es \\(200\\%\\) de la cantidad inicial (\\(100\\%\\) del inicial + \\(100\\%\\) del aumento = \\(200\\%\\) del inicial); En otras palabras, la cantidad se ha duplicado. Un aumento del \\(800\\%\\) significa que la cantidad final es 9 veces la original (\\(100\\%\\) + \\(800\\%\\) = \\(900\\%\\) = 9 veces más grande). Una disminución de \\(60\\%\\) significa que la cantidad final es \\(40\\%\\) del original (\\(100\\% - 60\\% = 40\\%\\)). Una disminución de \\(100\\%\\) significa que la cantidad final es cero (\\(100\\% - 100\\% = 0\\%\\)). En general, un cambio de \\(x\\) por ciento en una cantidad resulta en una cantidad final que es \\(100 + x\\) por ciento de la cantidad original (equivalentemente, \\(1 + 0.01\\) veces la cantidad original). (Bennett &amp; Briggs, 2008) 4.5.3 Porcentajes compuestos Los cambios porcentuales aplicados secuencialmente no se suman de la manera habitual. Por ejemplo, si el aumento del \\(10\\%\\) en el precio considerado antes (en el artículo de \\(\\$ 200\\), elevando su precio a \\(\\$220\\)) es seguido por una disminución del \\(10\\%\\) en el precio (una disminución de \\(\\$ 22\\)), el precio final será \\(\\$ 198\\) y no el precio original de \\(\\$ 200\\). La razón de la aparente discrepancia es que los cambios de dos por ciento (\\(+ 10\\%\\) y \\(-10\\%\\)) se miden en relación con diferentes cantidades (\\(\\$ 200\\) y \\(\\$ 220\\), respectivamente), y por lo tanto no se “cancelan”. En general, si un aumento de \\(x\\) por ciento es seguido por una disminución de \\(x\\) por ciento, y la cantidad inicial fue \\(p\\), la cantidad final es \\(p (1 + 0.01x) (1 - 0.01x) = p (1 - (0.01x )2)\\); Por lo tanto, el cambio neto es una disminución general de \\(x\\) por ciento de \\(x\\) por ciento (el cuadrado del cambio de porcentaje original cuando se expresa como un número decimal). Por lo tanto, en el ejemplo anterior, después de un aumento y una disminución de \\(x = 10\\) por ciento, la cantidad final, \\(\\$ 198\\), fue \\(10\\%\\) del \\(10\\%\\), o \\(1\\%\\), menor que la cantidad inicial de \\(\\$ 200\\). El cambio neto es el mismo para una disminución de \\(x\\) por ciento seguido por un aumento de \\(x\\) por ciento; La cantidad final es \\(p (1 + 0,01x) (1 - 0,01x) = p (1 - (0,01x)^2)\\). Esto se puede extender para un caso en el que no tenga el mismo porcentaje de cambio. Si el cambio de porcentaje inicial es \\(x\\) y el segundo cambio porcentual es \\(y\\), y la cantidad inicial es \\(p\\), entonces la cantidad final es \\(p (1 + 0.01x) (1 + 0.01y)\\). Para cambiar el ejemplo anterior, después de un aumento de \\(x = 10\\) por ciento y disminución de \\(y = -5\\) por ciento, la cantidad final, \\(\\$ 209\\), es \\(4,5\\%\\) más que la cantidad inicial de \\(\\$ 200\\). Como se muestra arriba, los cambios porcentuales se pueden aplicar en cualquier orden y tienen el mismo efecto. En el caso de los tipos de interés, una forma muy común pero ambigua de decir que una tasa de interés subió por ejemplo del \\(10\\%\\) anual al \\(15\\%\\) anual, es decir que la tasa de interés aumentó un \\(5\\%\\), lo que podría significar teóricamente que aumentó del 10% anual al 10,5% anual. Es más claro decir que la tasa de interés aumentó en 5 puntos porcentuales. La misma confusión entre los diferentes conceptos de porcentaje y puntos porcentuales puede potencialmente causar un malentendido mayor cuando los periodistas informan sobre los resultados electorales, por ejemplo, expresando tanto nuevos resultados como diferencias con resultados anteriores como porcentajes. Por ejemplo, si un partido obtiene el \\(41\\%\\) de los votos y se dice que es un aumento del \\(2,5\\%\\), ¿significa que el resultado anterior fue del \\(40\\%\\) (puesto que \\(41 = 40 \\times (1 + 2,5 / 100))\\) o del \\(38,5\\%\\)? Puesto que \\(41 = 38,5 + 2,5)\\)? En los mercados financieros, es común referirse a un aumento de un punto porcentual (por ejemplo, del \\(3\\%\\) anual al \\(4\\%\\) anual) como un aumento de “100 puntos básicos”. Referencias "],
["censo.html", "4.6 Censo", " 4.6 Censo En estudios estadísticos, es el caso especial de encuesta que consiste en observar cada miembro de una población con el fin de obtener de extraer de ellos la información de interés en las variables estudiadas para su posterior análisis e interpretación. Esta metodología presenta las siguientes características: No precisa técnicas de inferencia estadística. Los resultados obtenidos constituyen un marco muestral para estudios posteriores. Favorece la realización de estudios en muestras estadísticas obtenidas de la población censual. En general, son más costosos que los estudios muestrales, en todos los aspectos. Acarrea procesos de planeación, organización y control más complejos. Los resultados se obtienen a mediano y largo plazo, convirtiéndose en inoportunos y obsoletos. A pesar de presentar ciertas desventajas, cuando las circunstancias lo permitan (objetivos globales, poblaciones relativamente pequeñas y fácilmente identificables, suficientes recursos, etc.) deben utiizarse la metodología censual. (Särndal, Swensson, &amp; Wretman, 2003) y (Soto &amp; Franco, 2009). Referencias "],
["encuesta.html", "4.7 Encuesta", " 4.7 Encuesta Cuando se habla de encuesta o encuesta muestral, se definen las siguientes características metodológicas: Una encuesta tiene asociado un conjunto de elementos denominado población finita. Existe una regla de enumeración que define inequívocamente los elementos que pertenecen a la población. El objetivo de una encuesta es proveer información sobre la población finita en cuestión o sobre subpolaciones de interés, por ejemplo, “hombres” y “mujeres” como dos subpoblaciones de la población “todas las personas”. Tales subpoblaciones son llamados dominios de estudio o, eimplemente, dominios. El valor de una o más variables de estudio se asocia con cada elemento de población. El objetivo de un estudio es obtener información desconocida sobre características de la población o parámetros. Los parámetros son funciones de los valores de las variables de estudio. Estos son medidas cuantitativas desconocidas de interés para el investigador, por ejemplo, ingresos totales, ingresos promedio, rendimiento total, número de desempleados, para la población entera o para dominios específicos. En muchos estudios, acceder y observar elementos individuales de la población se establece a través de un marco muestral, un dispositivo que asocia los elementos de una población con las unidades muestrales en el marco. Una muestra (es decir, un subconjunto) de elementos se selecciona de la población. Esto puede hacerse seleccionando unidades muestrales en el marco. Se observan los elementos muestrales, es decir, para cada elemento en la muestra, se miden las variables de estudio y se registran sus valores. La medición está acorde con un plan de medición bien definido, especificado en términos de instrumentos de medición, una o más operaciones de medición, el orden entre ellos, y las condiciones bajo las cuales este procedimiento se lleva a cabo. Los valores registrados de la variable se usan para calcular estimaciones (puntuales) de los parámetros de interés de la población finita (totales, promedios, medianas, razones, coeficientes de regresión, etc.). También se calculan las estimaciones de la precisión de las estimaciones. Finalemente, las estimaciones se publican. "],
["poblacion.html", "4.8 Población", " 4.8 Población "],
["odds-ratio.html", "4.9 Odds ratio", " 4.9 Odds ratio En los últimos años los odds ratios se han utilizado ampliamente en informes médicos casi con certeza algunos aparecerán en el BMJ de hoy. Hay tres razones para esto. En primer lugar, proporcionan una estimación (con intervalo de confianza) para la relación entre dos variables binarias (“sí o no”). En segundo lugar, nos permiten examinar los efectos de otras variables sobre esa relación, utilizando la regresión logística. En tercer lugar, tienen una interpretación especial y muy conveniente en los estudios de casos y controles (tratados en una nota futura). "],
["rr.html", "4.10 RR", " 4.10 RR En estadística y epidemiología, el riesgo relativo es el cociente entre el riesgo en el grupo con el factor de exposición o factor de riesgo y el riesgo en el grupo de referencia (que no tiene el factor de exposición) como índice de asociación. El mejor estudio para calcular el riesgo relativo son los estudios prospectivos como el estudio de cohortes y el ensayo clínico, donde de la población se extraen dos muestras sin enfermedad o en las que no haya sucedido el evento: una expuesta al factor de riesgo y otra sin tal exposición. De cada muestra se calcula incidencia acumulada de expuestos y se calcula su cociente. "],
["cohorte.html", "4.11 Cohorte", " 4.11 Cohorte En estadística, marketing y demografía, una cohorte es un grupo de sujetos que comparten una característica definitoria (típicamente sujetos que experimentaron un evento común en un período de tiempo seleccionado, como nacimiento o graduación). La demografía a menudo contrasta perspectivas de cohortes y perspectivas de período. Por ejemplo, la tasa de fecundidad total de la cohorte es un índice del tamaño promedio de la familia completada para las cohortes de mujeres, pero dado que sólo puede conocerse para las mujeres que han terminado la crianza, no se puede medir para las mujeres actualmente fértiles. Se puede calcular como la suma de las tasas de fecundidad por edad específicas de la cohorte que se obtienen a medida que envejece a través del tiempo. En cambio, la tasa de fecundidad total del período utiliza las tasas actuales de fecundidad por edad para calcular el tamaño de la familia completada para una mujer ficticia si experimentara estas tasas de fecundidad a lo largo de su vida. Un estudio en una cohorte es un estudio de cohorte. Dos aspectos importantes de los estudios de cohortes son: Estudio Prospectivo de Cohorte: En este tipo de estudio, hay una colección de datos de exposición (datos basales) de los sujetos reclutados antes del desarrollo de los resultados de interés. Los sujetos son seguidos a través del tiempo (futuro) para grabar cuando el sujeto desarrolla el resultado de interés. Formas de seguimiento con los sujetos del estudio incluyen: entrevistas telefónicas, entrevistas cara a cara, exámenes físicos, pruebas médicas / de laboratorio y cuestionarios por correo [1]. Estudios Retrospectivos de Cohorte: Los estudios retrospectivos comienzan con sujetos que están en riesgo de tener el resultado o enfermedad de interés e identifica el resultado a partir de donde el sujeto es cuando el estudio comienza en el pasado del sujeto para identificar la exposición. Registros de uso retrospectivo: clínicos, educativos, certificados de nacimiento, certificados de defunción, etc., pero que pueden ser difíciles porque no puede haber datos para el estudio que se está iniciando. Estos estudios pueden tener múltiples exposiciones que pueden dificultar este estudio. [2] "],
["numeros-indices.html", " 5 Números Índices", " 5 Números Índices Los números índices son una medida estadística cuyo objetivo es analizar y comparar una magnitud simple o compleja del mismo tipo pero cuya medición se realiza en distintos momentos, lugares o circunstancias, es decir, evalúa dos situaciones diferentes respecto al tiempo o al espacio, tomando una de ellas como referencia. A partir de un número índice puede medirse el cambio que experimenta una variable o grupo de variables a través del tiempo o del espacio, refiriéndose siempre a una situación de base. Los números índices pueden tener distinta naturaleza: a) Naturaleza estadística, cuando se obtienen sin que medien las posibles relaciones funcionales en estudio y b) Naturaleza funcional, cuando se obtienen bajo el supuesto de que existe una relación funcional entre los valores de las variables y su entorno. Existe una clasificación de los números de acuerdo con su complejidad: "],
["indices-simples.html", "5.1 Índices simples", " 5.1 Índices simples Se refieren a una sola variable (unidimensional).Es la relación entre los valores de la variable correspondientes a dos épocas o lugares que desean compararse. La comparación se realiza entre el valor correspondiente a un periodo fijo, llamado periodo base y el valor alcanzado por la magnitud en un momento de interés \\(t\\). En forma matemática: \\[I_{t/0}(H)=\\frac{H_t}{H_0}\\] donde \\(H_t\\) es el valor de la variable en el tiempo de interés \\(t\\) y \\(H_0\\) es el valor de la variable en el tiempo 0, también llamado periodo base. \\(I_{t/0}(H)\\) define el índice de la magnitud \\(H\\). Realmente, lo que se hace al hallar el número índice de esta forma, es un cambio de variable, se pasa de la magnitud \\(H\\) a la magnitud \\(I(H)\\) y por tanto, todos los estadísticos que se definen para \\(H\\), estarán definidos para \\(I(H)\\) y viceversa. "],
["indices-complejos.html", " 6 Índices complejos", " 6 Índices complejos Los números índices complejos hacen referencia a varios elementos o conceptos a la vez y su evolución en el espacio o el tiempo. En este tipo de índices, se tiene en cuenta la evolución conjunta de todos los elementos a estudiar. Esto se puede hacer de dos formas: Suponiendo que cada elemento tiene la misma importancia relativa. En este caso estamos hablando de Índices complejos sin ponderar. Suponiendo que cada elemento tiene distinta importancia relativa. En cuyo caso hablaríamos de los Índices complejos ponderados. 6.0.1 Índices complejos sin ponderar Se crea una magnitud \\(H\\), la cual está formada por \\(K\\) magnitudes o elementos, es decir, \\(H = H^1,H^2,...,H^k,\\) si se quiere analizar la evolución de \\(H\\), se debe hacer en función de la evolución de las \\(K\\) magnitudes que la forman; es decir, el índice de \\(H\\) se obtiene en función de los índices de \\(H^i\\). Existen varias propuestas para este tipo de índices, como: 6.0.1.1 Índice de Sauerbeck: \\[I_{t/0}(H)=\\frac{1}{k}\\sum\\limits_{i=1}^kI_{t/0}(H^i)\\] 6.0.1.2 Índice media geométrica \\[I_{t/0}(H)=\\sqrt[\\leftroot{-2}\\uproot{2}k]{\\prod_{i=1}^k\\frac{H_t^i}{H_0^i}}\\] #### Índice media armónica \\[I_{t/0}(H)=\\frac{k}{\\sum\\limits_{i=1}^k\\frac{H_t^i}{H_0^i}}\\] 6.0.1.3 Índice media agregativa o índice de Bradstreet-Dûtot: \\[I_{t/0}(H)=\\frac{\\sum\\limits_{i=1}^k H_t^i}{\\sum\\limits_{i=1}^k H_0^i}\\] 6.0.2 Índices complejos ponderados A diferencia de los índices sin ponderar, los índices complejos ponderados tienen en cuenta la importancia relativa de los distintos elementos que componen la magnitud \\(H\\), se llamará a esta importancia relativa \\(w_i\\). Por construcción se debe de cumplir que: \\(\\sum_{i=1}^k w_t^i = 1\\) para todo \\(t\\). Dentro de los índices complejos ponderados más importantes se encuentran: 6.0.2.1 Índice de Laspeyres Se denota por \\(L\\) y se define como: \\[I_{t/0}(H)=\\sum_{i=1}^k w_0^i I_{t/0}(H^i) = \\sum_{i=1}^k w_0^i \\frac{H_t^a}{H_0^i}\\] Es decir, es la sumatoria de las importancias relativas de cada elemento \\(i\\), en el instante \\(0\\), (\\(w_0^i\\) ), multiplicadas por el cociente de los índices de la magnitud \\(i\\) en el instante \\(t\\) sobre el instante \\(0\\). Donde \\(w_0^i= \\frac{P_0^iQ_0^i}{\\sum_{i=1}^n P_0^iQ_0^i}\\) es decir, el precio de un producto multiplicado por la cantidad de dicho producto en el periodo base sobre la suma de los precios de todos los productos en consideración multiplicados por sus respectivas cantidades en el periodo base. El índice de Laspeyres es más sensible a valores extremos que los demás índices. 6.0.2.2 Indice de Paasche Se denota por \\(P\\) y se define como: \\[\\frac{1}{P_{t/0}(H)}=\\sum\\limits_{i=1}^k \\frac{w_t^i}{I_{t/0}H^i}=\\sum\\limits_{i=1}^k \\frac{w_t^iH_0^i}{H_t^i}\\] Es decir, la sumatoria del cociente entre las importancias relativas de los elementos en el instante \\(t\\) (\\(w_t^i\\)) y el cociente de los índices de la magnitud \\(i\\) en el instante \\(t\\) sobre el instante \\(0\\). Donde Donde \\(w_t^i= \\frac{P_t^iQ_t^i}{\\sum_{i=1}^n P_t^iQ_t^i}\\) es decir, el precio de un producto multiplicado por la cantidad de dicho producto en el periodo actual sobre la suma de los precios de todos los productos en consideración multiplicados por sus respectivas cantidades en el periodo actual. La diferencia principal entre los índices de Laspeyres y Paasche está en que las ponderaciones que usa Laspeyres son respecto al periodo base (\\(w_0^i\\) ), mientras que Pasche usa las ponderaciones en cada instante del tiempo (\\(w_t^i\\)); lo que dificulta el cálculo del índice de Paasche en la vida real. 6.0.2.3 Índice de Fisher Se denota por \\(F\\) y se define como la raíz cuadrada del producto del índice de Laspeyres multiplicado por el índice de Paasche, es decir: \\[F_{t/0}(H)=\\sqrt{L_{t/0}(H)\\times P_{t/0}(H)}\\] Nótese que este índice es un promedio (media geométrica) entre los dos índices explicados anteriormente. Esta formulación incorpora información de ponderaciones tanto del período base (por Laspeyres) como del período actual (por Paasche) 6.0.2.4 Índice de Edgeworth Se denota por \\(E\\) y se define como: \\[E_{t/0}(H)=\\sum\\limits_{i=1}^k w_0^i (H_t^i+H_0^i)\\] 6.0.2.5 Índice de Tornqvist Se denota por \\(T\\) y se define como: \\[T_{t/0}(H)=\\prod\\limits_{i=1}^k \\left( \\frac{H_t^i}{H_0^i} \\right)^{\\left[\\frac{w_t^i+w_0^i}{2}\\right]}\\] Es la media geométrica ponderada de la razón entre las magnitudes vigentes y las del año base. La diferencia básica de este índice con el índice de Fisher radica en que las ponderaciones del índice Tornqvist son el promedio de los pesos del período base y del período actual, mientras que en el índice de Fisher, ambos tenían el mismo peso. "],
["cambios-de-base.html", "6.1 Cambios de base", " 6.1 Cambios de base A medida que avanza el tiempo, se presentan cambios en los elementos que componen un índice; por ejemplo, cambios en la producción, cambios en los hábitos de consumo de la población, aparición y desaparición constante de productos, etc. Es decir, al cabo de cierto tiempo, el conjunto de elementos o el conjunto de pesos seleccionados para la construcción del índice puede que haya dejado de ser representativo y no se ajuste a la estructura de consumo actual. Cuando esto sucede, hay que renovar el índice con una nueva base. Al modificar la base de un número índice se produce una ruptura en la continuidad de la serie; que desde un punto de vista teórico, no admite solución cuando el cambio de base introduce también modificaciones tanto en los elementos como en las ponderaciones utilizadas para su cálculo. Pero como se necesitan series continuas que permitan realizar predicciones y estudios sobre la evolución histórica de los números índices, se busca un procedimiento que permita enlazar las series con el menor deterioro posible de las mismas. El procedimiento de cambio de base, consiste en buscar un coeficiente de enlace por el cual se multiplican los índices de los tiempos anteriores para hacerlos congruentes con la nueva base. De esta forma se “prolongan hacia atrás” los índices mediante la nueva base. Si lo que se desea es prolongar hacia delante los índices, se usa el coeficiente como divisor de los índices correspondientes a la nueva base. Se destacan los siguientes artículos que reúnen el material de índices: Allen, R.G.D. (1975) Index Numbers in Theory and Practice Aldine, Chicago. Bowley, A.L. (1928) ‘Notes on Index Numbers’, Economic Journal vol. 33, pp. 216-37. Chakrarty, S.R. (1990) Ethical Social Index Numbers, Springer, Berlin. Fisher, I. (1922) The Making of Index Numbers Houghton-Mifflin, Boston, Mass. "],
["escalas-de-medicion-o-clasificacion.html", " 7 Escalas de medición o clasificación", " 7 Escalas de medición o clasificación El nivel de medición o la escala de medición es una clasificación que identifica la naturaleza de la información dentro de los números asignados a las variables. El psicólogo Stanley Smith Stevens desarrolló la clasificación más conocida con cuatro niveles, o escalas, de medida: nominal, ordinal, intervalo y de razón. (Stevens, 1946) Este marco de distinción de los niveles de medición se originó en la psicología y es ampliamente criticado por los académicos de otras disciplinas (Michell, 1986). Otras clasificaciones incluyen las de Mosteller y Tukey, (Mosteller &amp; Tukey, 1977) y la de Chrisman. (Chrisman, 1998). Referencias "],
["tipologia-de-stevens.html", " 8 Tipología de Stevens", " 8 Tipología de Stevens El profesor Stevens propuso su tipología en un artículo titulado “On the theory of scales of measurement”(Stevens, 1946), publicado en la revista Science. En ese artículo se afirma que toda la medida en la ciencia se ha hecho usando cuatro tipos diferentes de escalas a las que llamó nominal, ordinal, de intervalo y de razón, unificando tanto las cualitativas (descritas por él como de tipo nominal) y las cuantitativas (el resto de sus escalas). El concepto de tipos de escala recibió todo el rigor formal del que carecía en su inicio con el trabajo matemático de los psicólogos Theodore Alper(Alper, 1985, 1987), Louis Narens(Narens, 1981a, 1981b) y Robert Duncan Luce(Luce, 1986, 1987). De hecho Luce (Luce, 2001) escribió: S.S. Stevens (Stevens, 1946, 1951, 1975) afirmó que al contar se tenía una escala de intervalo o de razón. Investigaciones posteriores han dado sentido a esta afirmación pero debido a sus intentos de invocar las ideas de tipo de escala es dudoso si se entendía a sí mismo… sé que ningún teórico de la medición acepta la amplia definición de medición dada por Stevens… en nuestra opinión, el único significado sensato de ‘regla’ es empíricamente comprobable por las leyes que se le atribuyen. Referencias "],
["comparacion.html", "8.1 Comparación", " 8.1 Comparación A continuación se presenta una comparación entre las distintas escalas propuestas por Stevens. Escala Propiedad de medida Operadores matemáticos Operaciones avanzadas Tendencia central Nominal Clasificación, afiliación =, != Agrupamiento Moda Ordinal Comparación, nivel &gt;, &lt; Ordenamiento Mediana Intervalo Diferencia, afinidad +, - Indicador Media, Desviación Razón Magnitud, cantidad *, / Cociente Media Geométrica, Coeficiente de variación "],
["escala-nominal.html", "8.2 Escala nominal", " 8.2 Escala nominal El tipo nominal diferencia entre objetos o temas basándose únicamente en sus nombres o (meta-)categorías y otras clasificaciones cualitativas a la que pertenecen; por lo tanto los datos dicotómicos involucran la construcción de clasificaciones, así como la clasificación de los objetos. El descubrimiento de una excepción a la clasificación puede ser vista como un progreso. Los números pueden ser usados para representar las variables, pero los números no tienen valor numérico o relación: por ejemplo, un identificador único global. Ejemplos de estas clasificaciones son el sexo, nacionalidad, origen étnico, idioma, género, estilo, especies biológicas, y la forma. Las escalas nominales fueron llamados a menudo escalas cualitativas, y las medidas tomadas en escalas cualitativas fueron llamados datos cualitativos. Sin embargo, el aumento de la investigación cualitativa ha hecho confuso este uso. Los números en la medida nominal se asignan como etiquetas y no tienen valor numérico específico o significado. Ningún cálculo matemático (+, -, x, etc.) puede realizarse de medidas nominales. El nivel nominal es la medición de nivel más bajo utilizado desde un punto de vista estadístico. 8.2.1 Operaciones matemáticas La igualdad y otras operaciones que puedan ser definidas en términos de igualdad, tales como desigualdad y pertenencia son las únicas operaciones no triviales que genéricamente pueden aplicarse a objetos de tipo nominal. 8.2.2 Medidas de tendencia central La moda es una medida de tendencia central que se acepta en la escala de tipo nominal. Por otra parte, la mediana no tiene sentido en esta escala puesto que la clasificación no tiene sentido para el tipo nominal. "],
["escala-ordinal.html", "8.3 Escala ordinal", " 8.3 Escala ordinal El tipo ordinal obedece a una estructura matemática de orden (primero, segundo, tercero, etc.) mediante la cual los datos pueden ser ordenados, pero todavía no permite un grado de diferencia entre ellos. Los ejemplos incluyen, por un lado, los datos dicotómicos con valores dicotómicos (o dicotomizadas) tales como ‘enfermo’ vs. ‘saludable’ en la medición de la salud, ‘culpable’ vs. ‘inocente’ al hacer juicios en los tribunales, ‘equivocado/falso’ vs. ‘correcto/verdadero’ en la medición de la verdad justa, y, por otro lado, no dicotómicas de datos que constan de un espectro de valores, tales como ‘completamente de acuerdo’, ‘mayormente de acuerdo’, ‘mayormente en desacuerdo’, ‘completamente en desacuerdo’ cuando se mide la opinión. 8.3.1 Medidas de tendencia central La mediana y la moda se permiten como medidas de tendencia central mientras que la media (el promedio), no se permite. En 1946, Stevens observó que la medición psicológica, tal como la medición de opiniones, por lo general funciona con escalas ordinales; por lo tanto, las medias y las desviaciones estándar no tienen validez, sino que se pueden utilizar para obtener ideas sobre cómo mejorar la operacionalización de las variables utilizadas en los cuestionarios. La mayoría de los datos psicológicos recogidos por los instrumentos psicométricos y pruebas, medición y otras habilidades cognitivas, son ordinales, aunque algunos teóricos han argumentado que puedan ser tratados como escalas de intervalo o de razón. Sin embargo, hay poca evidencia prima facie que sugiera que tales atributos son algo más que ordinales(Cliff, 2014; Cliff &amp; Keats, 2003; Michell, 2008). En particular, las puntuaciones de CI reflejan una escala ordinal, en los cuales todos los resultados son significativos sólo para comparación(Lord, Novick, &amp; Birnbaum, 1968). No hay cero absoluto, y una diferencia de 10 puntos puede llevar a diferentes significados en diferentes puntos de la escala. Referencias "],
["escala-de-intervalo.html", "8.4 Escala de intervalo", " 8.4 Escala de intervalo El tipo de escala de intervalo permite el grado de diferencia entre los elementos, pero no la relación entre ellos. Los ejemplos incluyen la temperatura con escala Celsius, que tiene dos puntos definidos (el punto de congelación y ebullición del agua a condiciones específicas) y luego separados en 100 intervalos, las fechas cuando se miden desde una época arbitraria (tales como AD), el porcentaje tal como un porcentaje de retorno de un valor, la ubicación en coordenadas cartesianas, y la dirección que se mide en grados a partir del norte verdadero o magnético. Las proporciones no son significativas puesto que 20°C no puede decirse que sea “dos veces más caliente”, que 10°C, ni la multiplicación/división puede realizarse entre dos fechas directamente. Sin embargo, las razones de diferencias pueden ser expresadas; Por ejemplo, una diferencia puede ser el doble de la otra. Las variables de tipo de intervalo a veces también se denominan “variables de escala”, pero el término matemático formal es un espacio afín (en este caso una línea análoga). 8.4.1 Tendencia central y dispersión estadística La moda, la mediana y la media aritmética se permite medir como medidas de tendencia central de variables en la escala de intervalo, mientras que las medidas de dispersión estadística incluyen el rango y la desviación estándar. Debido a que que sólo se puede dividir por diferencias, no es posible definir medidas que requieran una serie de razones, como el coeficiente de variación. De manera más sutil, mientras que se pueda definir momentos sobre el origen, sólo los momentos centrales son significativos, ya que la elección del origen es arbitraria. Pueden definirse momentos estandarizados, desde que las razones de las diferencias sean significativas, pero no se puede definir el coeficiente de variación, ya que la media es un momento sobre el origen, a diferencia de la desviación estándar, que es (la raíz cuadrada de) un momento central. "],
["escala-de-razon.html", "8.5 Escala de razón", " 8.5 Escala de razón El tipo de escala de razón toma su nombre del hecho de que la medición es la estimación de la relación entre una magnitud de una cantidad continua y una magnitud unitaria de la misma clase (Michell, 1997, 1999). Una escala de razón posee un significado (único y no arbitrario) del valor cero. La mayoría de mediciones en las ciencias físicas y la ingeniería se hace en escalas de razón. Los ejemplos incluyen masa, longitud, duración, ángulo del plano, energía y la carga eléctrica. En contraste con las escalas de intervalo, las proporciones son ahora significativas puesto que tener un punto cero no arbitrario hace que sea significativo decir, por ejemplo, que un objeto tiene “dos veces la longitud” de otro. Muy informalmente, muchas escalas de razón se pueden describir como la especificación de “cuánto hay” de algo (es decir, una cantidad o magnitud) o “cuántos hay” (a cuenta). La escala de temperatura Kelvin es una escala de razón porque tiene un único punto cero no arbitrario, llamado cero absoluto. 8.5.1 Tendencia central y dispersión estadística La media geométrica y la media armónica se permiten para medir la tendencia central, además de la moda, la mediana y la media aritmética. El rango estudentizado y el coeficiente de variación permiten medir la dispersión estadística. Todas las medidas estadísticas se permiten porque todas las operaciones matemáticas necesarias se definen para la escala de razón. Referencias "],
["tipologias-en-debate-con-la-de-stevens.html", " 9 Tipologías en debate con la de Stevens", " 9 Tipologías en debate con la de Stevens Mientras la tipología de Stevens está ampliamente adoptada, sigue siendo desafiada por otros teóricos(Michell, 1986), en particular en los casos de los tipos nominales y ordinales(Velleman &amp; Wilkinson, 1993). Luce (Luce, 1986) se opuso al uso de la palabra medición en relación con el tipo nominal, pero Stevens (Stevens, 1975) dice de su propia definición de medición que “la asignación puede ser cualquier regla consistente. La única regla no permitida sería la asignación aleatoria, para cantidades aleatorias, lo que no sería una regla”. Sin embargo, la llamada medición nominal involucra asignación arbitraria, y la “transformación permitida” es cualquier número en otro. El uso de la media como una medida de la tendencia central para el tipo ordinal es aún discutible entre quienes aceptan la tipología de Stevens. De todos modos, muchos científicos del comportamiento utilizan la media para datos ordinales. Esto se justifica a menudo sobre la base de que el tipo ordinal en la ciencia del comportamiento está, de hecho, en algún lugar entre los ordinales verdaderos y los tipos de intervalo; a pesar de que la diferencia de intervalo entre dos rangos ordinales no es constante, a menudo es del mismo orden de magnitud. Por ejemplo, las aplicaciones de los modelos de medición en contextos educativos a menudo se refieren a que las puntuaciones totales tienen una relación bastante lineal con mediciones en el rango de una evaluación. Por lo tanto, algunos argumentan que tanto el tiempo como la diferencia desconocida del intervalo entre rangos de escala ordinal no es muy variable, las estadísticas de escala de intervalo tales como las medias cobran sentido en variables de escala ordinal. L. L. Thurstone avanzó hacia el desarrollo de una justificación para obtener el tipo de intervalo, basado en la ley de juicio comparativo(Thurstone, 1927). Un mayor progreso fue hecho por Georg Rasch (Rasch, 1993), que desarrolló el modelo de Rasch probabilístico que proporciona una base teórica y la justificación de la realización de mediciones de nivel de intervalo de frecuencias de observaciones como las puntuaciones totales de las evaluaciones. Referencias "],
["indicadores.html", " 10 Indicadores", " 10 Indicadores Este capítulo se basa especialmente en el trabajo de Pérez (2002), Martínez Rizo (2010), Rizo (2005) y Salas, Garvi, Martín, &amp; others (2011) y se enfoca en indicadores sobre temas educativos. Referencias "],
["definicion.html", "10.1 Definición", " 10.1 Definición No existe una definición concreta, por parte de organismo alguno sobre los indicadores, algunos de los más importantes son los que se presentan a continuación. La Organización de las Naciones Unidas (ONU) definen los indicadores como: “Herramientas para clarificar y definir, de forma más precisa, objetivos e impactos (…) son medidas verificables de cambio o resultado (…) diseñadas para contar con un estándar contra el cual evaluar, estimar o demostrar el progreso (…) con respecto a metas establecidas, facilitan el reparto de insumos, produciendo (…) productos y alcanzando objetivos”. (Assembly, 1999) De igual forma, Bauer en 1966 utiliza una definición que utilizan muchos autores: “Los indicadores (…) son estadísticas, serie estadística o cualquier forma de indicación que nos facilita estudiar dónde estamos y hacia dónde nos dirigimos con respecto a determinados objetivos y metas, así como evaluar programas específicos y determinar su impacto”. (Horn, 1993) Algo interesante es que la Organización para la Cooperación y Desarrollo Económicos - OECD tiene un programa para la información relevante y precisa sobre la educación a nivel mundial. Infortunadamente, Colombia no hace parte de los miembros de este programa denominado The Indicators of Education Systems (INES) programme. Los indicadores son variables o instrumentos de medida que intentan representar un constructo generalmente de forma cuantitativa. Compara entre dos o más tipos de datos para elaborar una medida cuantitativa o una observación cualitativa. Dicha comparación arroja un valor, una magnitud o un criterio dotado de un significado para quien lo analiza. Este resultado puede ser usado para escribir y comprender el funcionamiento de la calidad de un sistema o una actividad en concreto. Su importancia radica en que nos encontramos inmersos en una cultura en el que se privilegia el valor asignado a los objetos, logros o situaciones que sólo adquieren sentido con respecto al valor relativo de las cosas y ese valor puede medirse mediante los indicadores. Referencias "],
["caracteristicas-de-los-indicadores.html", "10.2 Características de los indicadores", " 10.2 Características de los indicadores Pertenecer a un marco conceptual o teórico que lo dote de sentido. De ser posible, debe establecerse una estructura que lo ubique en un marco explicativo i.e. modelo presión-estado-respuesta (PER) que usa la OECD para los indicadores medio ambientales. Ser específicos bajo la naturaleza del tema que se pretenda medir. Debe medir objetivos o metas claros. Ser explícitos en el sentido de que su nombre de una idea precisa de si se trata de un valor relativo o absoluto, de una tasa, de una razón, de un índice, etc. De igual forma debe especificar la población de interés, si la información es global o está desagregada por sexo, edad, años, etc. Ser perdurable para poder compararlos a través del tiempo Ser relevantes y oportunos con el fin de que describan con precisión la situación del fenómeno observable con el fin de establecer acciones. Comúnmente un indicador solo no permite la medición completa de un fenómeno por lo que pertenece a una batería de indicadores que en conjunto permiten analizar apropiadamente una situación de estudio. Ser claro, fácil de comprender. Para cada indicador se acostumbra tener una definición, fórmula de cálculo y metadatos para su mejor entendimiento y socialización. Ser confiable y consistente en su metodología de cálculo con el fin de que distintas personas, con diferentes herramientas, en circunstancias similares puedan medirlo. Ser trazable para que pueda hacerse seguimiento a través del tiempo. Ser válido, confiable, comparable y factible en términos de que su costo sea razonable. Ser sensible a cambios del fenómeno Deben ser medibles a partir de un acervo de datos disponible "],
["diferencia-entre-datos-medidas-estadisticas-e-indicadores.html", "10.3 Diferencia entre datos, medidas, estadísticas e indicadores", " 10.3 Diferencia entre datos, medidas, estadísticas e indicadores Dato: es sólo el insumo para el proceso de construcción de conocimiento y/o estadísticas. El dato per se está desprovisto de sentido y su significado se lo provee el contexto en el que se enmarca. Únicamente de esta forma se convierte en información. Medida: impone parámetros de cuantificación (peso, volumen, cantidad, etc.). Permite evaluar la importancia de un objeto o fenómeno comparándolo con otro de la misma especie. Mediante las medidas, los objetos permiten ser claramente procesados y valorados. Todos los indicadores son medidas mas no todas las medidas son indicadores puesto que no todas las medidas indican algo en sentido utilitario y semántico. Estadística: las estadísticas tienen numerosos propósitos tales como el conteo, medida y descripción de un fenómeno. Se caracterizan por ser exhaustivas, permanentes, técnicas y orientadoras de los procesos para su obtención. Para que una estadística pueda considerarse indicador esponda a ciertos requerimientos de información representativos del desarrollo económico, social o humano. La construcción de indicadores requiere un marco legal, programático y normativo (nacional y/o internacional) que establece las necesidades de información para medir o analizar la situación de la educación, economía, la sociedad, la población o el medio ambiente, respecto a determinados valores o metas perseguidos. Indicadores: sus características son: Ser exclusivo de los temas de política o de administración Ser dinámicos y estar sometidos a continua revisión Ser materia de política pública, de modo que su definición no sea tarea exclusiva de los estadísticos Ser relevantes para la toma de decisiones y definición de políticas Ser oportuno para la evaluación y monitoreo de los asuntos de administración pública o privada Ser analítico de los fenómenos bajo observación Ser comparativo tanto en el tiempo como en el espacio, por lo cual tienen que estar disponibles para diferentes regiones o países y para cada año en un periodo de tiempo determinado. "],
["tipos-de-indicadores.html", "10.4 Tipos de indicadores", " 10.4 Tipos de indicadores Pueden diferenciarse dos criterios para clasificar los indicadores: A partir de la dimensión que se quiere expresar (educativa, social, económica, etc.). Estas dimensiones únicamente difieren por las unidades de medida que usan, así, los indicadores económicos suelen utilizar productos y/o unidades monetarias, los indicadores sociales lo hacen en personas, etc. Naturalmente puede hablarse de indicadores positivos o negativos si se pretenden destacar los avances o rezagos de algún fenómeno de estudio. En este sentido, por ejemplo, puede hablarse de índice de alfabetismo o analfabetismo. De la misma manera existen indicadores indeterminados que son aquellos de los cuales no puede esperarse que alcancen su valor superior o inferior i.e. tasa de matrícula en educación superior, en el sentido de que, si bien se espera que alcance el 100%, no necesariamente es positivo puesto que es imposible que toda la población alcance este nivel de estudios. También existen indicadores absolutos y relativos que son aquellos cuya evaluación depende de un valor determinado (un máximo o mínimo que debe cumplirse) o de la posición relativa de, por ejemplo, una institución de educación superior con respecto a otras. Los indicadores absolutos dependen de una meta a cumplir (alfabetismo, asistencia escolar, cobertura académica, etc.) mientras que los indicadores relativos ubican la posición de una unidad geográfica con respecto a otras unidades. En la administración pública se acostumbra a hablar de una clasificación distinta de los indicadores que obedece al lenguaje propio del área. Allí los indicadores se organizan por ser: de gestión y de resultado, de insumos y productos, costos, procesos, productos y resultados, insumos, etc. Existen también los indicadores de contexto que, aunque no reflejan de forma directa la situación del sector que se quiere evaluar, son parte del ambiente que afecta la situación social, económica o ambiental y pueden modificar el comportamiento de los fenómenos bajo observación. El producto interno bruto (PIB) per cápita, la tasa de fecundidad y la de crecimiento de la población, entre otros, se consideran como indicadores de contexto. Desde el tipo de medida o procedimiento estadístico con que se obtiene. Aquí también pueden diferenciarse dos tipos: indicadores objetivos y subjetivos. Los objetivos se basan en evidencias externas independientes del informante (como podría ser el nivel educativo de la población), suponiendo que los métodos de captación, procesamiento y divulgación de la información son objetivos. Los subjetivos son juicios, casi siempre en modo y en concepto, y reflejan percepciones y opiniones de la población con respecto a su situación, a la de la sociedad o al país. Aquí los indicadores pueden ser clasificados como simples (si se trata de una estadística univariada y/o poco complicada), o sintéticos (si se habla de un agregado que sintetiza la situación global de un sector determinado y que incluye varios componentes del mismo). "],
["limitaciones-de-los-indicadores.html", "10.5 Limitaciones de los indicadores", " 10.5 Limitaciones de los indicadores Entre la problemática que puede presentarse para su identificación e integración está la selección de los que se consideren más adecuados para cada objetivo, existen diferentes actores, como los sectores estadístico, público, privado, social o académico que no comparten las mismas necesidades de información ni persiguen las mismas metas, lo cual dificulta lograr unanimidad en su definición. Su naturaleza cuantitativo hace que se generen indicadores únicamente de aquello que puede ser medido en cantidad. Des esta forma, su uso presupone que las metas de instituciones y dependencias públicas, así como sus niveles de logro están disponibles, son identificables y cuantificables en planes y programas de gobierno y que no hay contradicciones entre los mismos. Si dependen de objetivos que son cambiantes, por ejemplo en cada nueva administración, no sólo se modifica el tipo de indicadores que deben ser empleados, sino también la disponibilidad de datos para conformarlos, lo que conlleva un ajuste permanente de las fuentes de información. "],
["marco-internacional-de-los-indicadores.html", "10.6 Marco internacional de los indicadores", " 10.6 Marco internacional de los indicadores Desde mediados del siglo pasado, la ONU empredió la tarea de fomentar la generación de estadísticas e indicadores para medir la calidad de vida en muchos aspectos en los países que conforman esta organización. Poco a poco se han ido conformando infraestructuras estadísticas en cada país que han permitido describir, comparar y evaluar su situación con respecto al mundo. Cuenta de este proceso en el campo educativo lo pueden dar diferentes documentos útiles que se relacionan con la construcción de indicadores, dentro de los que se destacan: Education Indicators: An International Perspective. (Matheson &amp; others, 1996) de la National Center for Education Statistics, International education indicators (Bottani, 1996) y Handbook for internationally comparative education statistics: concepts, standards, definitions and classifications de la OECD (Economic Co-operation &amp; Development, 2004), Integrated and Coordinated Implementation of and Follow-up to the Outcomes of the Major United Nations Conferences and Summits in the Economic, Social and Related fields de la ONU (Assembly, 2010), Educational indicators: What’s to be measured? del Banco Mundial (Vos, 1996), Education Indicators Technical guidelines y A Framework for Assessing the Quality of Education Statistics (Patel, Hiraga, Wang, Drew, &amp; Lynd, 2003) de la UNESCO (Indicators, 2009), Summary report of the invitational roundtable on statistical indicators for the quality assessment of higher/tertiary education institutions: Ranking and league table methodologies de la ASA (Merisotis, 2002) y Trends in education and training (Ferriss, 1978), entre otros. Sin embargo, el texo más importante pues constituye el documento teórico y metodológico mejor enfocado es Statistical indicators for the economic and social sciences. (Horn, 1993) De igual forma en la siguiente página se encuentra material copioso sobre el tema. La Universidad de Harvard dispuso este sitio para reunir dicha información. http://guides.library.harvard.edu/c.php?g=309951&amp;p=2070359 Igualmente la UNESCO mantiene un sitio que almacena información sobre evaluación de educación a nivel mundial: http://portal.unesco.org/en/ev.php-URL_ID=34356&amp;URL_DO=DO_TOPIC&amp;URL_SECTION=201.html El siguiente título no se encontró y quizás tenga información importante: Johnstone, J.N. (1981) Indicators of Education Systems UNESCO, Paris. La Comisión de Estadística de las Naciones Unidas https://unstats.un.org/home/1 está integrada por expertos representantes de las oficinas de estadística de varios países. Esta Comisión se formó con el objetivo de que definiera los indicadores que servirían para realizar el seguimiento de los compromisos que los países asumieron en las cumbres mundiales. Este trabajo ha permitido, por una parte, tener un listado básico de indicadores ligados a las metas de las cumbres y, por otra, llevar a cabo una evaluación del nivel de madurez que, en materia estadística, han alcanzado las naciones. Actualmente, la Comisión de Estadística cuenta con un conjunto mínimo de 15 indicadores de cada país para el seguimiento de las cumbres mundiales; por su parte, el Comité de Asistencia para el Desarrollo de la OCDE, en cooperación con la ONU, el BM y el FMI, tiene trabajados 21 indicadores de las metas de desarrollo internacional; la Comisión de Desarrollo Sustentable de las Naciones Unidas maneja 57 indicadores, y finalmente la ONU posee un conjunto básico de indicadores sociales que dan cuenta del acceso de la población a los servicios. La OCDE desarrolla y fomenta, entre sus países miembros, una segunda generación de indicadores que muestran no sólo los resultados de la implantación de políticas,sino también los costos, insumos y procesos que participan en la efectividad de las políticas públicas. Referencias "],
["sobre-la-escritura-como-antecedente-historico-de-la-informacion.html", " 11 Sobre la escritura como antecedente histórico de la información", " 11 Sobre la escritura como antecedente histórico de la información Indefectiblemente la escritura es un insumo muy importante para la información en la forma digital que conocemos hoy en día. Su desarrollo histórico dio pie a transformaciones sucesivas que con el avance de la tecnología fueron poco a poco convirtiendo a la escritura en registros digitales. La historia del libro está íntimamente ligada con el proceso de información y con la cadena de valor del dato pues sin ellos hubiese sido imposible contar con la materia prima propia de la comunicación que son las palabras y los números. Los registros escritos que datan de la prehistoria constituyen una aproximación histórica certera de la cultura humana. Si bien es cierto que las primeras formas de escritura fueron protocuneiformes, pictográficas e ideográficas, este fue el génesis del proceso de documentación con el que el ser humano dio cuenta de su cotidiano vivir. Las diferentes culturas desarrollaron sistemas de escritura a su manera: la escritura china, por ejemplo, era gráfica y sus inscripciones originales eran oraculares en huesos y caparazones de tortuga; las escrituras precolombinas, en especial la maya, contaron con una estructura gramatical bien establecida y un sistema de numeración propio y existen sustentos físicos de su lenguaje. El rápido desarrollo del lenguaje significó que la escritura también avanzara en la medida en que las lenguas se expandían a lo largo y ancho del planeta. Familias de lenguas antiguas En un principio no existían más que juglares, trovadores y escribientes encargados de difundir el conocimiento. Sin embargo, este sistema era poco efectivo puesto que el alcance era bastante limitado. Sólo hasta la aparición de la imprenta fue posible reproducir textos e imágenes sobre papel de forma mecánica. A pesar de que los romanos contaban con sellos que imprimían sobre arcilla hacia el 435 a de C. y los chinos tenían tipos móviles que imprimían sobre papel de arroz hacia el 1045, la imprenta moderna se atribuye al descubrimiento de la tipografía que hiciera Johannes Gutenberg en el año 1450 y su testimonio más insigne es la biblia de 42 líneas. Biblia de 42 líneas de Gutenberg En Colombia, esos desarrollos tecnológicos de la imprenta iniciados por el maguntino Gutenmberg llegaron después de la conquista, exactamente en la colonización y con su proceso más contundente que era la evangelización. Al catolicismo se le endilgó la transmisión del conocimiento al Nuevo Mundo y la herramienta más expansiva era la imprenta. El advenimiento de la imprenta en el continente supuso también que fuera posible compartir el conocimiento de nativos y criollos. Es así que, por ejemplo, la Declaración de los Derechos del Hombre y del Ciudadano se imprimió en la Imprenta Patriótica de la Nación. Con el devenir de la tecnología, ha sido posible que la información se expanda y que los procesos de reconocimiento de caracteres permitan digitalizar imágenes y textos impresos en los libros. De esta forma se produce la datificación del libro y se genera el siguiente paso para cuantificar, tabular y analizar este conocimiento. En Colombia, este proceso de digitalización de textos impresos aún no termina y avanza paquidérmicamente. Es indiscutible que es menester datificar el gran acervo bibliográfico que aun existe en papel y que constituye en un corpus vital para el análisis de información. "],
["antecedentes-historicos-de-concepto-de-numero.html", " 12 Antecedentes históricos de concepto de número", " 12 Antecedentes históricos de concepto de número Este texto no se elaboró siguiendo una pesquisa minuciosa sino que se construyó con base en lo encontrado principalmente en A. Santiago &amp; Santiago (2011). Intuitivamente el concepto de número se asocia con la habilidad de contar y comparar la cantidad de elementos entre dos conjuntos de objetos similares. Las primeras civilizaciones debieron determinar comparaciones entre conjuntos o de conocer cuántos elementos formaban una colección de cosas. El conteo se inició mediante la utilización de objetos físicos que el ser humano encontraba a su alrededor (huesos, palos, piedras, etc.) como el de Lebombo con 29 muescas grabadas en un hueso de babuino que tiene cerca de 37000 años de antigüedad (Stewart &amp; Stewart, 2008) Trozo de palo encontrado en Lebombo) Los sistemas de numeración de muchas de las familias lingüísticas hablan acerca de que el conteo estuvo asociado a los dedos, situación por la que los sistemas de base decimal y vigesimal se impusieron. La transición hacia símbolos numerales se justifica en la organización gubernamental y su origen estaría en primitivas figuras que servían para el recuento de diferentes bienes como los encontrados en Mesopotamia, iscritos en tablillas de arcilla. Los símbolos numéricos mesopotámicos son los más antiguos y muchos de ellos no se usaron exclusivamente para la contabilidad o el comercio sino para la agrimensura o la astronomía (Verdejo Páez &amp; others, 1851). Desde hace 5000 años la mayoría de civilizaciones cuentan como lo hacemos hoy en día, es decir, como una representación de los números naturales. Sin embargo pueden caracterizarse en tres categorías: Notación aditiva. Acumulan los símbolos de todas las unidades, decenas, centenas, etc. necesarios hasta completar el número. De este tipo son los sistemas egipcio, hitita, romano, griego, armenio, judío, etc. Notación híbrida. Combinan el principio aditivo con el multiplicativo. Por ejemplo, en el sistema de notación aditiva 500 se representa con cinco símbolos de cien. En éstos se utiliza la combinación del cinco y el cien. De este tipo son: chino clásico, asirio, armenio, etíope y maya. El sistema de numeración maya usó símbolos para el “1”, “5” y “0”, siendo éste el primer uso documentado del cero (año 36 a de C). Notación posicional. La posición de las cifras indica si son unidades, decenas, centenas, o en general la potencia de la base. Tres culturas junto con la india lograron desarrollar un sistema así: El sistema Chino (300 a de C) que no disponía de “0”“, el sistema Babilónico (2000 a de C) con dos símbolos, de base 10 aditivo hasta el 60 y posicional (de base 60) en adelante, sin”0&quot; hasta el 300 a de C. Referencias "],
["papiro-ahmesrhind-y-las-fracciones-egipcias.html", "12.1 Papiro Ahmes/Rhind y las fracciones egipcias", " 12.1 Papiro Ahmes/Rhind y las fracciones egipcias Este papiro data del 2000 al 1800 a de C considera las fracciones unitarias (inversas de los naturales 1/20) que se representan con un signo oval encima del número, la fracción 2/3 que se representa con un signo especial y en algunos casos fracciones del tipo $ n / n + 1$. Hay tablas de descomposición de \\(2 / n\\) desde n=1 hasta n=101, por ejemplo \\(2 / 5 = 1 / 3 + 1 / 15\\) ó \\(2 / 7 = 1 / 4 + 1 / 28\\). Papiro Ahmes/Rhind "],
["documentos-cuneiformes.html", "12.2 Documentos cuneiformes", " 12.2 Documentos cuneiformes Tablilla cuneiforme Hammurabi En las tablillas cuneiformes de la dinastía Hammurabi (1800-1600 a de C) aparece el sistema posicional, antes referido, extendido a las fracciones. Para calcular recurrían, como nosotros antes de disponer de máquinas, a las numerosas tablas de que disponían: De multiplicar, de inversos, de cuadrados y cubos, de raíces cuadradas y cúbicas, de potencias sucesivas de un número dado no fijó, etc. "],
["cero.html", "12.3 Cero", " 12.3 Cero Sobre el siglo III a de C, en Grecia, se comenzó a representar la nada mediante una “o” que significa oudos ‘vacío’, y que no dio origen al concepto de cero como existe hoy en día. La idea del cero como concepto matemático parece haber surgido en la India mucho antes que en ningún otro lugar. La única notación ordinal del viejo mundo fue la sumeria, donde el cero se representaba por un vacío. El número 605 en números Khmer de la inscripción Sambor (el 605 en la era Saka corresponde al 683 después de Cristo). El material más próximo conocido donde se usa el cero como una figura decimal. En América, la primera expresión conocida del sistema de numeración vigesimal prehispánico data del siglo III a de C. Se trata de una estela olmeca tardía, la cual ya contaba tanto con el concepto de “orden” como el de “cero”. Los mayas inventaron cuatro signos para el cero; los principales eran: el corte de un caracol para el cero matemático, y una flor para el cero calendárico (que implicaba, no la ausencia de cantidad, sino el cumplimiento de un ciclo). "],
["sistema-indo-arabigo-en-occidente.html", "12.4 Sistema indo - arábigo en Occidente", " 12.4 Sistema indo - arábigo en Occidente Numerosos autores del siglo XIII contribuyeron a esta transmisión, entre los que se destacan: Alexandre de Villedieu (1225), Sacrobosco (circa 1195, o 1200-1256) y sobre todo Leonardo de Pisa (1180-1250). Este último, conocido como Fibonacci, quien viajó por Oriente y aprendió de los árabes el sistema posicional hindú. Escribió un libro, El Liber abaci, que trata en el capítulo I sobre la numeración posicional, en los cuatro siguientes las operaciones elementales, en los capítulos VI y VII las fracciones: comunes, sexagesimales y unitarias (¡no usa los decimales, principal ventaja del sistema!), y en el capítulo XIV los radicales cuadrados y cúbicos. Una página del Liber Abaci de la Biblioteca Nazionale di Firenze No aparecen los números negativos, que tampoco consideraron los árabes, debido a la identificación de número con magnitud (¡obstáculo que duraría siglos!). A pesar de la ventaja de sus algoritmos de cálculo, se desataría por diversas causas una lucha encarnizada entre abacistas y algoristas, hasta el triunfo final de estos últimos. "],
["particularidades-sociales-de-los-numeros.html", "12.5 Particularidades sociales de los números", " 12.5 Particularidades sociales de los números Los números naturales nacen por la necesidad de contar Los números fraccionarios por la necesidad de medir partes de un todo, y compartir Los enteros negativos por fenómenos de doble sentido: izquierda-derecha, arriba-abajo, pérdida-ganancia Los números reales por la necesidad de medir segmentos Los números complejos por exigencias de resolver ecuaciones algebráicas "],
["una-breve-historia-de-la-visualizacion-de-datos.html", " 13 Una breve historia de la visualización de datos", " 13 Una breve historia de la visualización de datos Este resumen condensa ideas del libro Handbook of Data Visualization de Chen, Härdle y Unwin. (Chun-houh Chen, 2008) y de A Brief History of Data Visualization de Michael Friendly. (Friendly, 2008) Referencias "],
["introduccion.html", "13.1 Introducción", " 13.1 Introducción Comúnmente se pìensa que los gráficos estadísticos y la visualización de datos son desarrollos relativamente modernos en la estadística. Sin embargo, la representación gráfica de la información cuantitativa tiene raíces profundas. Estas raíces llegan a la historia de las primeras cartografías y representaciones visuales, y más tarde a la cartografía temática, estadísticas y gráficos estadísticos, con aplicaciones e innovaciones en muchos campos de la medicina y la ciencia que a menudo se entrelazan entre sí. También se conectan con el aumento del pensamiento estadístico y la recopilación de datos generalizado para la planificación y el comercio hasta el siglo XIX. En el camino, una variedad de avances contribuyeron al uso generalizado de la visualización de datos en la actualidad. Estos incluyen tecnologías para dibujar y reproducir imágenes, avances en matemáticas y estadística, y nuevos desarrollos en la recolección de datos, observación empírica y grabación. "],
["hitos.html", "13.2 Hitos", " 13.2 Hitos Al organizar esta historia, fue útil dividirla en épocas, cada una de las cuales resultó ser descriptible por temas y etiquetas coherentes. Esta división es, por supuesto, algo artificial, pero ofrece la oportunidad de caracterizar los logros en cada período de una manera general, antes de describir algunos de ellos con más detalle. La siguiente figura proporciona una visión general gráfica de las épocas que se describen en las siguientes subsecciones, abajo está la frecuencia de eventos considerados hitos en los periodos de esta historia. Por el momento, basta señalar las etiquetas adheridas a estas épocas, un constante aumento desde principios del siglo 18, con un curioso movimiento a partir de entonces. En el panorama más amplio -reconociendo la historia de la visualización de datos- resulta que muchos de los ítems de los hitos tienen una historia que contar: ¿Qué motivó este desarrollo? ¿Cuál fue el objetivo de la comunicación? ¿Cómo se relaciona con otros desarrollos? ¿Cuáles fueron los precursores? ¿Cómo se ha utilizado o reinventado esta idea hoy? Cada sección trata de ilustrar los temas generales con algunos ejemplos. En particular, esta cuenta intenta relatar algunas historias representativas de estos períodos, en lugar de tratar de ser exhaustivas. Figura 1. Distribución del tiempo de eventos considerados hitos en la historia de la visualización de datos) "],
["principios-del-siglo-17-primeros-mapas-y-diagramas.html", "13.3 Principios del siglo 17: Primeros mapas y diagramas", " 13.3 Principios del siglo 17: Primeros mapas y diagramas Las primeras semillas de la visualización surgieron en los diagramas geométricos, en las tablas de las posiciones de las estrellas y otros cuerpos celestes, y en la elaboración de mapas para ayudar en la navegación y la exploración. La idea de las coordenadas fue utilizada por los agrimensores egipcios antiguos en la disposición de las ciudades, las posiciones terrenales y celestiales se localizaron por algo similar a la latitud y la longitud al menos en el 200 a de C, y la proyección del mapa de una tierra esférica en latitud y longitud por Claudius Ptolemy [c. 85 - c. 165] en Alejandría serviría como referencia hasta el siglo XIV. Entre las representaciones gráficas más tempranas de la información cuantitativa se encuentra un gráfico anónimo de la serie temporal del siglo X de la posición cambiante de los siete cuerpos celestes más prominentes sobre el espacio y el tiempo (Figura 2), descrito por Funkhouser (1936) y reproducido en Tufte (1983, página 28). El eje vertical representa la inclinación de las órbitas planetarias, el eje horizontal muestra el tiempo, dividido en treinta intervalos. Es notable la variación sinusoidal, con periodos diferentes, como es el uso de una rejilla, lo que sugiere una noción implícita de un sistema de coordenadas, y algo parecido al papel cuadriculado, ideas que no estarían completamente desarrolladas hasta 1600-1700. Figura 2. Movimientos planetarios mostrados como inclinaciones cíclicas a través del tiempo, por un astrónomo desconocido, apareciendo en un apéndice del siglo X a los comentarios de A. T. Macrobius sobre Cicerón en In Somnium Scripionus. En el siglo XVI, las técnicas e instrumentos para la observación precisa y la medición de las cantidades físicas y la posición geográfica y celestial estaban bien desarrolladas (por ejemplo, un “cuadrante de la pared” construido por Tycho Brahe [1546-1601], cubriendo toda una pared en su observatorio). Particularmente importantes fueron el desarrollo de la triangulación y otros métodos para determinar con exactitud las localizaciones de mapas. Además, vemos ideas iniciales para capturar imágenes directamente (la cámara oscura, usada por Reginer Gemma-Frisius en 1545 para registrar un eclipse del sol), la grabación de funciones matemáticas en tablas (tablas trigonométricas de Georg Rheticus, 1550), y el primer atlas cartográfico moderno (Teatrum Orbis Terrarum de Abraham Ortelius, 1570). Estos primeros pasos comprenden los inicios de la visualización de los datos. "],
["medicion-y-teoria.html", "13.4 1600 - 1699: Medición y teoría", " 13.4 1600 - 1699: Medición y teoría Entre los problemas más importantes del siglo XVII estaban los relacionados con la medición física del tiempo, la distancia y el espacio para la astronomía, la topografía, la elaboración de mapas, la navegación y la expansión territorial. En este siglo también se observó un nuevo crecimiento en la teoría y el amanecer de la aplicación práctica: el surgimiento de la geometría analítica y los sistemas de coordenadas (Descartes y Fermat), teorías de errores de medición y estimación (pasos iniciales de Galileo en el análisis de observaciones sobre la estrella de Tycho Brahe de 1572, el nacimiento de la teoría de la probabilidad (Pascal y Fermat) y los comienzos de las estadísticas demográficas (John Graunt) y la “aritmética política” (William Petty), La tierra, los impuestos, el valor de los bienes, etc. con el fin de comprender la riqueza del Estado. A principios de este siglo, Christopher Scheiner (1630, grabaciones de 1611) introdujo una idea que Tufte (1983) llamaría más tarde el principio de “pequeños múltiplos” para mostrar las cambiantes configuraciones de las manchas solares a lo largo del tiempo (Figura 3). Las imágenes representan las grabaciones de manchas solares del 23 de octubre de 1611 hasta el 19 de diciembre de ese año. La clave grande en la parte superior izquierda identifica siete grupos de manchas solares por las letras A-F. Estos grupos se identifican de forma similar en las 37 imágenes más pequeñas, agrupadas de izquierda a derecha y de arriba a abajo. Figura 3. Representación de Scheiner de 1626 de los cambios en las manchas solares con el tiempo. Otro ejemplo notable (Figura 4) muestra un gráfico de 1644 de Michael Florent van Langren [1600-1675], un astrónomo flamenco de la corte de España, que se cree es la primera representación visual de datos estadísticos (Tufte, 1997, p. 15). En ese momento, la falta de un medio fiable para determinar la longitud en el mar dificultaba la navegación y la exploración. Este gráfico de línea unidimensional muestra las 12 estimaciones conocidas de la diferencia de longitud entre Toledo y Roma, y el nombre del astrónomo (Mercator, Tycho Brahe, Ptolomeo, etc.) que proporcionó cada observación. Figura 4. Gráfico de 1644 de Langren de las determinaciones de la distancia, en longitud, de Toledo a Roma. La distancia correcta es 16º30’. "],
["nuevas-formas-graficas.html", "13.5 1700 - 1799: Nuevas formas gráficas", " 13.5 1700 - 1799: Nuevas formas gráficas Con algunos rudimentos de teoría estadística, datos de interés e importancia, y la idea de representación gráfica por lo menos algo establecida, el siglo 18 fue testigo de la expansión de estos aspectos a nuevos dominios y nuevas formas gráficas. En la cartografía, los fabricantes de mapas empezaron a tratar de mostrar algo más que una simple posición geográfica en un mapa. Como resultado, se inventaron nuevas representaciones de datos (isolíneas y contornos), y la cartografía temática de las cantidades físicas se arraigó. Hacia finales de este siglo, se ven los primeros intentos de cartografía temática de datos geológicos, económicos y médicos. Los gráficos abstractos y los gráficos de las funciones se hicieron más difundidos, junto con los comienzos tempranos de la teoría estadística (error de la medida) y la colección sistemática de datos empíricos. Cuando se empezaron a recolectar otros datos (económicos y políticos), se inventaron nuevas formas visuales para retratarlos, de modo que los datos podían «hablar a los ojos». Por ejemplo, el uso de isolines para mostrar contornos de igual valor en una cuadrícula de coordenadas (mapas y gráficos) fue desarrollado por Edmund Halley (1701). La Figura 5, que muestra líneas isogónicas de declinación magnética igual está entre los primeros ejemplos de cartografía temática, superponiendo datos en un mapa. Los mapas de contorno y los mapas topográficos fueron introducidos un poco más tarde por Phillippe Buache (1752) y Marcellin du Carla-Boniface (1782). Figura 5. Una porción del Nuevo y Correcto Mar que ilustra las variaciones de la brújula en el Océano Occidental y Austral de Edmund Halley, 1701. El uso de figuras geométricas (cuadrados o rectángulos) y cartogramas para comparar áreas o magnitudes demográficas por Charles de Fourcroy (1782) y August FW Crome (1785) proporcionó otra codificación visual novedosa para datos cuantitativos usando cuadrados superpuestos para comparar las áreas de Estados europeos. También cabe resaltar la contribución del francés Charles Minard (1781 - 1870) a quien se debe su notable contribución en el campo de las gráficas informativas en ingeniería civil y estadística. Una de sus representaciones es la que se muestra en la figura 6. Figura 6. Gráfico que muestra el número de las fuerzas francesas en su marcha hacia Moscú y durante la retirada, por Charles Minard. También contiene información ambiental como la temperatura por fecha.. "],
["albores-de-las-graficas-modernas.html", "13.6 1800 - 1850: Albores de las gráficas modernas", " 13.6 1800 - 1850: Albores de las gráficas modernas Con la fertilización proporcionada por las innovaciones anteriores de diseño y técnica, la primera mitad del siglo 19 fue testigo de un crecimiento explosivo en gráficos estadísticos y cartografía temática, a un ritmo que no se igualaría hasta los tiempos modernos. En los gráficos estadísticos, se inventaron todas las formas modernas de visualización de datos: diagramas de barras y sectores, histogramas, gráficos de líneas y gráficos de series temporales, gráficos de contornos, diagramas de dispersión, etc. En la cartografía temática, la cartografía pasó de mapas únicos a atlas completos, describiendo datos sobre una amplia variedad de temas (económicos, sociales, morales, médicos, físicos, etc.) e introdujo una amplia gama de nuevas formas de simbolismo. Durante este período, también aparecieron regularmente en las publicaciones científicas análisis gráficos de fenómenos naturales y físicos (líneas de magnetismo, meteorología, mareas, etc.). En octubre de 1831, el primer caso de cólera asiático se produjo en Gran Bretaña, y más de 52.000 personas murieron en la epidemia que se produjo durante los siguientes 18 meses aproximadamente. Las epidemias subsiguientes de cólera en 1848-1849 y 1853-1854 produjeron peores muertes similares, pero la causa de la enfermedad fue desconocida hasta 1855 cuando el Dr. John Snow produjo su famoso mapa de puntos mostrando muertes debidas al cólera agrupado alrededor de la bomba de Broad Street en Londres. Este fue, de hecho, un descubrimiento gráfico, pero ocurrió al final del período, aproximadamente 1835-1855, lo que marca un punto culminante en la aplicación de la cartografía temática a los temas humanos (sociales, médicos, étnicos). El primer mapa conocido de enfermedad del cólera (Figura 7), debido al Dr. Robert Baker (1833), muestra los distritos de Leeds “afectados por el cólera” en el particularmente grave brote de 1832. Figura 7. Una parte del mapa del cólera del Dr. Robert Baker de Leeds, 1833, que muestra los distritos afectados por el cólera. Aproximadamente al mismo tiempo, ~1830-1850, el uso de gráficos comenzó a ser reconocido en algunos círculos oficiales para la planificación económica y estatal: ¿donde construir ferrocarriles y canales? ¿Cuál es la distribución de las importaciones y las exportaciones? Este uso de los métodos gráficos no estuvo mejor ilustrado que en las obras de Charles Joseph Minard [1781-1870], cuyas prodigiosas invenciones gráficas llevaron a Funkhouser (1937) a llamarlo el Playfair de Francia. Para ilustrar, se eligió (con cierta dificultad) un “tableau-gráfico” de 1844 (Figura 8) de Minard, un progenitor temprano del mosaico moderno. En la superficie, las parcelas de mosaico descienden de los gráficos de barras, pero Minard introdujo dos innovaciones simultáneas: el uso de barras divididas y de anchura proporcional para que el área tuviera una interpretación visual concreta. El gráfico muestra el transporte de mercancías comerciales a lo largo de una ruta de canal en Francia por barras divididas de anchura variable. En esta imagen la anchura de cada barra vertical muestra la distancia a lo largo de esta ruta; Los segmentos de barra divididos tienen una cantidad de bienes de varios tipos (mostrada por sombreado), de manera que el área de cada segmento rectangular es proporcional al coste de transporte. Figura 8. Tableau Graphique de Minard, que muestra el transporte de mercancías comerciales a lo largo del Canal du Centre (Chalon-Dijon). Las paradas intermedias están espaciadas por la distancia, y cada barra está dividida por el tipo de mercancías, así que el área de cada azulejo representa el coste del transporte. Las flechas muestran la dirección del transporte. "],
["el-era-dorada-de-las-graficas-estadisticas.html", "13.7 1850 - 1900: El era dorada de las gráficas estadísticas", " 13.7 1850 - 1900: El era dorada de las gráficas estadísticas A mediados del siglo XIX, se habían establecido todas las condiciones para el rápido crecimiento de la visualización, una “tormenta perfecta” para los gráficos de datos. En toda Europa se establecieron oficinas estatales oficiales de estadística, en reconocimiento de la creciente importancia de la información numérica para la planificación social, la industrialización, el comercio y el transporte. La teoría estadística, iniciada por Gauss y Laplace, y extendida al ámbito social por Guerry y Quetelet, proporcionó los medios para dar sentido a grandes conjuntos de datos. Las escalas y las formas de gráficos y mapas también se transformaron para una variedad de propósitos, dando lugar a gráficos semi-logarítmicos para mostrar el cambio porcentual en las mercancías en el tiempo, gráficos log-log para mostrar relaciones multiplicativas, mapas anamórficos por E mile Cheysson, utilizando deformaciones de tamaño espacial para mostrar una variable cuantitativa (por ejemplo, la disminución en el tiempo para viajar de París a varios lugares en Francia más de 200 años) y diagramas de alineación o Nomogramas utilizando conjuntos de ejes paralelos. Se ilustra esta parte de la edad de oro con la figura 9, un gráfico de tour-de-force para la determinación de la desviación magnética en el mar en relación con la latitud y longitud sin cálculo (“L’Abaque Triomphe”) por Charles Lallemand (1885), director General de la medición geodésica de altitudes en toda Francia, que combina muchas variables en un nomograma multifuncional, utilizando 3D, yuxtaposición de mapas anamórficos, coordenadas paralelas y cuadrículas hexagonales. Figura 9. L’abaque de bateau Le Triomphe de Lallemand, que permite la determinación de la desviación magnética en el mar sin cálculo. En 1859, Florence Nightingale usa estadísticas de víctimas de la guerra de Crimea para influenciar a la opinión pública y a la Oficina de Guerra. Ella muestra víctimas mes a mes en un gráfico circular diseñado por ella, la “rosa de Nightingale”, precursor del gráfico de torta. Ella es la primera mujer miembro de la Sociedad Real de Estadística y la primer miembro extranjera de la Asociación Americana de Estadística. Figura 10. *“Rosa de Nightingale”. Gráfico circular diseñado por Florence Nightingale El descubrimiento gráfico no estadístico más notable de Francis Galton (1822-1911) fue el del modelo “anticiclónico” (en sentido contrario a las agujas del reloj) de vientos alrededor de regiones de baja presión, combinado con rotaciones en el sentido de las agujas del reloj alrededor de zonas de alta presión. El trabajo de Galton sobre patrones climáticos comenzó en 1861 y fue resumido en Meteorographica (1863). Contiene una variedad de ingeniosos gráficos y mapas (más de 600 ilustraciones en total), uno de los cuales se muestra en la Figura 10. Este notable gráfico, uno de una pantalla de dos páginas en forma de enrejado, muestra observaciones sobre la presión barométrica, dirección del viento, lluvia y temperatura a partir de 15 días en diciembre de 1861. Para cada día, la cuadrícula 3 × 3 muestra mapas esquemáticos de Europa, presión cartográfica (fila 1), viento y lluvia (fila 2) y temperatura (fila 3), por la mañana, tarde y noche (columnas). Se puede observar claramente la serie de áreas negras (baja presión) en las tablas barométricas durante la primera mitad del mes, correspondientes a las flechas en el sentido contrario a las agujas del reloj en las cartas de viento, seguido por un cambio a áreas rojas (alta presión ) y más flechas en el sentido de las agujas del reloj. Figura 11. Una página de la tabla de tiempo multivariante de Galton 1863 de Europa que muestra la presión barométrica, la dirección del viento, la lluvia, y la temperatura para el mes de diciembre de 1861. El pináculo de este período de álbumes estadísticos patrocinados por el Estado es, sin duda, los Albums de Statistique Graphique publicados anualmente por el ministerio francés de obras públicas desde 1879-1897 bajo la dirección de E mile Cheysson. Figura 12. Mouvement des voyageurs et des marchandises dans les principales stations de chemin de fer en 1882. Escala: 2mm2 = 10.000 pasajeros o toneladas de flete. 1900 - 1950: El oscurantismo moderno Si a finales del siglo XIX se trataba de la “edad de oro” de los gráficos estadísticos y la cartografía temática, los 1900s tempranos puede ser llamados el “oscurantismo moderno” de la visualización. Hubo pocas innovaciones gráficas y, a mediados de la década de 1930, el entusiasmo por la visualización que caracterizó a finales del siglo XIX había sido suplantado por el aumento de la cuantificación y por modelos formales, a menudo estadísticos, en las ciencias sociales. Los números, las estimaciones de los parámetros y, especialmente, los errores estándar fueron precisos. Las imágenes eran, bueno, sólo cuadros: bonitos o evocadores, tal vez, pero incapaces de indicar un “hecho” a tres o más decimales. O eso le pareció a muchos estadísticos. Sir Arthur Bowley representó el valor total de las exportaciones de Gran Bretaña e Irlanda entre 1855 y 1899. Se discutió si las exportaciones se habían vuelto estacionarias en los últimos años y la conclusión de Sir Robert Giffen (1899), basada exclusivamente en las tablas de promedios de cinco mencionó que “el único signo de estacionariedad es un aumento a un ritmo menor en los últimos períodos que en los períodos anteriores”. Para responder a esto, representó los datos brutos, junto con las curvas de la media móvil en tres, cinco y diez años. Los promedios móviles de tres y cinco años muestran fuertes evidencias de un ciclo de aproximadamente 10 años, y señaló que “no puede sostenerse ningún argumento que no tenga en cuenta el ciclo del comercio, que no se elimina hasta que se adopten los promedios decenales”. Para ello, tomó promedios de períodos sucesivos de 10 años a partir de 1859 y dibujó una curva a mano alzada “manteniéndose lo más cerca posible de los puntos, sin hacer cambios repentinos en la curvatura”, dando la curva gruesa en la figura 12. La conclusión de Robert y la evidencia de un ciclo de 10 años debe mucho a este tratamiento gráfico. Figura 13. La demostración de Arthur Bowley de los métodos de suavizar un gráfico de serie de tiempo. Los promedios móviles de tres, cinco y diez años se comparan con una curva a mano alzada trazada a través de cuatro puntos que representan los promedios de períodos sucesivos de diez años. "],
["renacimiento-de-la-visualizacion-de-datos.html", "13.8 1950 - 1975: Renacimiento de la visualización de datos", " 13.8 1950 - 1975: Renacimiento de la visualización de datos Todavía bajo la influencia del zeitgeist formal y numérico de mediados de los años 30 encendido, la visualización de los datos comenzó a levantarse de la latencia en los mediados de los años 60. Esto fue impulsado en gran parte por tres desarrollos significativos: En Estados Unidos, John W. Tukey [1915-2000], en un documento de referencia, El Futuro de la Análisis de Datos, hizo un llamamiento para el reconocimiento del análisis de datos como una rama legítima de la estadística distinta de la Estadística matemática; En breve, comenzó la invención de una amplia variedad de formas gráficas nuevas, simples y eficaces, bajo el rótulo de “Exploratory Data Analysis” (EDA) - gráficos de tallo-hoja, diagramas de cajas, raíces colgantes, pantallas de dos vías y etc., muchos de los cuales entraron en el vocabulario estadístico y en la implementación del software. La estatura de Tukey como estadístico y el alcance de su enfoque informal, robusto y gráfico para el análisis de datos fueron tan influyentes como sus innovaciones gráficas. Aunque no se publicó hasta 1977, los capítulos del libro de Tukey EDA (Tukey, 1977) se distribuyeron ampliamente cuando comenzaron a aparecer en 1970-1972, y comenzaron a hacer el análisis gráfico de datos interesante y respetable otra vez. En Francia, Jacques Bertin [1918-] publicó la monumental Semiologie Graphique (Bertin, 1967). Para algunos, esto parecía hacer para los gráficos lo que Mendeleev había hecho para la organización de los elementos químicos, es decir, organizar los elementos visuales y perceptuales de los gráficos de acuerdo con las características y las relaciones en los datos. En un vapor paralelo pero separado, un enfoque exploratorio y gráfico de datos multidimensionales (“L’analyse des donnees”) iniciado por Jean-Paul Benzécri [1932-] proporcionó a los estadísticos franceses y otros estadísticos europeos una alternativa, visualmente basada en lo que la estadística se trata. Pero las habilidades de mapas y gráficos dibujados a mano se habían marchitado durante el “oscurantismo” de los gráficos (aunque casi todas las figuras de la EDA de Tukey fueron dibujadas a mano por intención). El procesamiento informático de datos estadísticos comenzó en 1957 con la creación de FORTRAN, el primer lenguaje de alto nivel para la informática. A finales de la década de 1960, las computadoras universales generalizadas de computadoras centrales ofrecían la posibilidad de construir viejas y nuevas formas gráficas mediante programas informáticos. Las aplicaciones estadísticas interactivas y los verdaderos gráficos de alta resolución se desarrollaron pero tomarían un tiempo para entrar en el uso común. Al final de este período, empezarían las intersecciones y colaboraciones significativas: (a) investigación de la ciencia informática (herramientas de software, lenguaje C, UNIX, etc.) en Bell Laboratories y en otros lugares combinaría fuerzas con (b) Desarrollos en el análisis de datos (EDA, psicometría, etc.) y (c) tecnología de visualización y entrada (plotters, terminales gráficos, tabletas digitalizadoras, ratón, etc.). Estos desarrollos proporcionarán nuevos paradigmas, lenguajes y paquetes de software para expresar ideas estadísticas e implementar gráficos de datos. A su vez, conducirían a un crecimiento explosivo en nuevos métodos y técnicas de visualización. "],
["presente-visualizacion-de-datos-interactiva-y-dinamica.html", "13.9 1975 - presente: visualización de datos interactiva y dinámica", " 13.9 1975 - presente: visualización de datos interactiva y dinámica Durante el último cuarto del siglo XX, la visualización de datos se ha convertido en un área de investigación madura, vibrante y multidisciplinar, como se puede ver en este Manual Chun-houh Chen (2008), y herramientas de software para una amplia gama de métodos de visualización y tipos de datos están disponibles para cada computadora. Sin embargo, es difícil proporcionar una visión suscinta de los desarrollos más recientes en la visualización de datos, porque son tan variados, se han producido a un ritmo acelerado y en un rango más amplio de disciplinas. También es muy difícil destacar los acontecimientos más significativos, que pueden ser vistos como tales en una historia posterior centrada en este período reciente. Con este descargo de responsabilidad, se destacan algunos temas importantes: el desarrollo de sistemas informáticos estadísticos altamente interactivos. Inicialmente, esto significó en gran medida que fuesen controlados por comandos, los sistemas directamente programables (APL, S), en contraposición a la compilación, al procesamiento por lotes; nuevos paradigmas de manipulación directa para el análisis de datos visuales (vinculación, cepillado, selección, enfoque, etc.); nuevos métodos para la visualización de datos de gran dimensión (el tour grande (Asimov, 1985), la matriz del diagrama de dispersión (Tukey y Tukey, 1981), el diagrama de coordenadas paralelas (Inselberg, 1985, Wegman, 1990), los diagramas de extensión (Young, 1994a).); la invención (o reinvención) de técnicas gráficas para datos discretos y categóricos; la aplicación de métodos de visualización a una serie cada vez más amplia de problemas sustantivos y estructuras de datos, y la atención considerablemente mayor a los aspectos cognitivos y perceptivos de la visualización de datos. Esta evolución de los métodos y técnicas de visualización probablemente dependía de los avances en la infraestructura teórica y tecnológica, tal vez más que en períodos anteriores. Algunos de estos son: ingeniería de software estadístico y gráfico a gran escala, tanto comercial (por ejemplo, SAS) como no comercial (por ejemplo, Lisp-Stat, R). Estos han sido a menudo significativamente apalancados por los estándares de código abierto para la presentación de la información y la interacción (por ejemplo, Java, Tcl/Tk); Extensiones del modelado estadístico lineal clásico a dominios cada vez más amplios (modelos lineales generalizados, modelos mixtos, modelos para datos espaciales / geográficos, etc.). Aumento considerable de la velocidad y capacidad de procesamiento de la computadora, permitiendo métodos computacionales intensivos (métodos bootstrap, análisis Bayesiano MCMC, etc.), acceso a problemas masivos de datos (medidos en terabytes) y datos en tiempo real. Los avances en esta área continúan presionando para nuevos métodos de visualización. Desde principios de los años setenta hasta mediados de los ochenta, muchos de los avances en gráficos estadísticos se referían a gráficos estáticos para datos cuantitativos multidimensionales, diseñados para permitir al analista ver relaciones en dimensiones progresivamente más altas. Las ideas más antiguas de técnicas de reducción de dimensiones (análisis de componentes principales, escalamiento multidimensional, análisis discriminante, etc.) dieron lugar a generalizaciones de proyectar un conjunto de datos de altas dimensiones a vistas “interesantes” de bajas dimensiones, expresadas por varios índices numéricos que podrían ser pptimizado (persecución por proyección) o explorado interactivamente (gran recorrido). El desarrollo de métodos generales para tablas multidimensionales de contingencia comenzó a principios de los años 70, con Leo Goodman (1970), Shelly Haberman (1973) y otros (Bishop et al., 1975) exponiendo los fundamentos de los modelos log-lineales. A mediados de los años ochenta, se desarrollaron algunas técnicas iniciales especializadas para visualizar tales datos (diagrama cuadriplicados (Fienberg, 1975), diagrama de asociación (Cohen, 1980), diagrama de mosaico (Hartigan y Kleiner, 1981) y diagrama de tamiz (Riedwyl y Schu ̈pbach, 1983)), basado en la idea de mostrar frecuencias por área (Friendly, 1995). De éstas, las extensiones del mosaico (Friendly, 1994, 1999) han demostrado ser de utilidad general, y ahora están ampliamente implementadas en una variedad de software estadístico, más completamente en el paquete vcd (Meyer et al., 2005) de R. Se puede argumentar que el mayor potencial para el crecimiento reciente en la visualización de datos provino del desarrollo de métodos gráficos dinámicos, permitiendo la manipulación instantánea y directa de objetos gráficos y propiedades estadísticas relacionadas. Una instancia temprana fue un sistema para interactuar con tramas de probabilidad (Fowlkes, 1969) en tiempo real, eligiendo un parámetro de forma de una distribución de referencia y transformaciones de potencia ajustando un control. El primer sistema general para la manipulación de datos de gran dimensión fue PRIM-9, desarrollado por Fishkeller, Friedman y Tukey (1974), y proporcionando herramientas dinámicas para Proyectar, Rotar (en 3D), Aislar (identificar subconjuntos) y Enmascarar datos en hasta 9 dimensiones. A mediados de los años ochenta, a medida que las estaciones de trabajo y la tecnología de pantalla se volvieron más baratas y más potentes, el software de escritorio para gráficos dinámicos se hizo más accesible (por ejemplo, MacSpin, Xgobi). Muchos de estos desarrollos hasta ese momento se detallan en los capítulos de Dynamic Graphics for Statistics (Cleveland y McGill, 1988) En los años noventa, varias de estas ideas fueron reunidas para proporcionar sistemas más generales para gráficos dinámicos e interactivos, combinados con la manipulación y análisis de datos en ambientes computacionales coherentes y extensibles. La combinación de todos estos factores era más poderosa e influyente que la suma de sus partes. Por ejemplo, Lisp-Stat (Tierney, 1990) y su progenie (Arc, Cook y Weisberg (1999), ViSta, Young (1994b)) proporcionaron un entorno orientado a objetos fácilmente extensible para la informática estadística. En estos sistemas, los widgets (deslizadores, cuadros de selección, listas de selección, etc.), gráficos, tablas, modelos estadísticos y el usuario, todos comunicados a través de mensajes, actuados por quien era un “oyente” designado y tenían un método para responder a la mayoría de las ideas y métodos detrás de los gráficos interactivos actuales que se describen e ilustran en Young et al. (2006). Referencias "],
["linea-de-tiempo-de-la-estadistica.html", " 14 Línea de tiempo de la Estadística", " 14 Línea de tiempo de la Estadística "],
["bibliografia-para-consultar-no-encontrada-en-internet.html", " 15 Bibliografía para consultar no encontrada en Internet", " 15 Bibliografía para consultar no encontrada en Internet The handbook of social indicators: sources, characteristics, and analysis. (Rossi &amp; Gilmartin, 1980) Data analysis and regression: a second course in statistics Para la parte matemático-estadística, podría consultarse sobre Foundations of measurement (Quizás se relacione con Teoría de la medida) Statistics for management decisions, (Plane &amp; Oppermann, 1977) Referencias "],
["referencias.html", "Referencias", " Referencias "]
]
